{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DevOps Package Introduction","text":""},{"location":"#setting-the-stage","title":"Setting the Stage","text":"<p>Have you or your engineers ever made comments like this?</p> <ul> <li>It\u2019s difficult to keep track of what still needs to be done in this project</li> <li>I wish I could develop new features faster</li> <li>I need to somehow figure out how to do more work with less people</li> <li>I\u2019m too busy fighting fires, I don\u2019t have time to improve my processes</li> <li>It takes too long to deploy bugfixes in the field</li> <li>I have a testing process, but it\u2019s tedious and time consuming</li> <li>I don\u2019t have a good systematic process for testing my code before deployment</li> </ul> <p>Well, one way to address these kinds of problems is a set of practices called  DevOps.</p> <p></p>"},{"location":"#what-is-devops","title":"What is DevOps?","text":"<p>DevOps is the union of  development and IT  operations to continually, reliably, and quickly provide product to customers.   At B&amp;R: </p> <ul> <li>Product = AS project </li> <li>Dev = Applications Engineer tasks </li> <li>Ops = Project Manager / Commissioning Engineer tasks</li> </ul> <p>DevOps involves strategies like increasing the visibility of tasks and metrics, dividing and planning work in measurable chunks, optimizing team and project architecture, automated testing and reporting, etc to accomplish goals such as increasing productivity, increasing the frequency of deployments, increasing code quality, reducing response time for bugfixes, reducing fire-fighting, and so on. </p>"},{"location":"#current-situation","title":"Current Situation","text":"<p>Many people agree that the DevOps mindset is a favorable way to work, but integrating new practices  requires bandwidth that most of us don\u2019t have. As a result, inefficient workflows remain in place.</p> <p></p>"},{"location":"#br-devops-package","title":"B&amp;R DevOps Package","text":"<p>To address this, B&amp;R has put together this DevOps package. The mission and purpose of this package is:  To significantly reduce the barriers to entry of DevOps strategies into the day-to-day workflow of Automation Studio project development, in order to increase the efficiency, quality, and maintainability of the resulting applications. </p>"},{"location":"#value-proposition","title":"Value Proposition","text":"<p>DevOps adds significant value to you in the following ways:</p> <ul> <li>Frequent deployments</li> <li>Increased productivity</li> <li>Spend less time fire-fighting</li> <li>Faster time to market</li> <li>Respond rapidly to required changes</li> <li>Higher code quality</li> <li>Quickly deliver bugfixes</li> <li>\u2026 and more</li> </ul> <p>B&amp;R has invested the time to research DevOps practices and is ready to incorporate them into the development of your machine software.</p>"},{"location":"#package-contents","title":"Package Contents","text":"<p>The DevOps package includes material for the following subjects:</p> <ul> <li>Project Management</li> <li>Version Control</li> <li>Automation &amp; Build Server</li> <li>Testing</li> </ul> <p>For each of these subjects, the package contains  reference material  and  template files.</p> <p>The reference material explains the conceptual information behind the subject, including what it is, why it\u2019s important, how you can implement it, and other various tips and tricks.</p> <p>Wherever applicable, we provide template files to expedite your implementation of that part of the DevOps process.</p> <p>Throughout the package we identify the tools and resources that we use at B&amp;R, but of course you are free to utilize whatever tools you prefer to accomplish each aspect of the DevOps process.</p> <p>Lastly, everything within the DevOps package is  free to use!</p>"},{"location":"#lets-get-started","title":"Let\u2019s Get Started!","text":"<p>To get started, take a look through the package contents on the left and dive in to your topic of interest. The documentation will guide you through the topic and explain all template files as they come up.  </p> <p>     We reserve the right to change the content of any of this material without prior notice. The information contained herein is believed to be accurate as of the date of publication, however, B&amp;R makes no warranty, expressed or implied, with regards to the products or the documentation contained within this document. B&amp;R shall not be liable in the event if incidental or consequential damages in connection with or arising from the furnishing, performance or use of these products. The software names\\, hardware names and trademarks used in this document are registered by the respective companies.     Copyright \u00a9 B&amp;R \u2013 Subject to change without notice </p>"},{"location":"AutomationBuildServer/","title":"Automation &amp; Build Server","text":""},{"location":"AutomationBuildServer/#definitions","title":"Definitions","text":""},{"location":"AutomationBuildServer/#build-server","title":"Build Server","text":"<ul> <li>A build server is an isolated production environment where software projects are compiled and built.</li> <li>The code is pulled directly from a source control repository prior to build.</li> </ul>"},{"location":"AutomationBuildServer/#automation-server","title":"Automation Server","text":"<ul> <li>An automation server is used to automate tasks and processes.</li> <li>The automation server monitors the source control repo. As soon as a code change is checked into the repo (or at a specific time interval), the automation server will automatically trigger the following:<ul> <li>Check out the latest version of the code from the source control repo</li> <li>Compile the code on the build server</li> <li>Initiate the automated unit/integration tests</li> <li>Communicate the results (pass/fail) to the interested parties via email, Teams, Confluence, etc</li> <li>Initiate automated deployment</li> <li>\u2026 and so on</li> </ul> </li> <li>The automation server is essentially the \u201cpuppet master\u201d of the automations within the DevOps process</li> </ul>"},{"location":"AutomationBuildServer/#benefits","title":"Benefits","text":"<ul> <li>By building the project and running tests in an isolated production environment, you will be testing against a collection of known dependencies. In other words, you avoid the \u201cit fails for you, but it works on my PC\u201d situation</li> <li>By automating the deployment pipeline with a build server, developers quickly receive feedback about whether their changes introduced a problem into the system<ul> <li>The sooner a problem is identified, the easier/cheaper it is to fix</li> <li>The build server provides a clear paper trail for what change introduced a problem</li> </ul> </li> <li>When used in combination with proper version control practices, the latest version of code will always be in a releasable state</li> <li>Since the releases are automated and not manual, release steps are consistent and no steps are forgotten</li> </ul>"},{"location":"AutomationBuildServer/#target-applications","title":"Target Applications","text":"<ul> <li>Any and all applications can benefit from the incorporation of a build and automation server</li> <li>Any steps that are triggered automatically are inherently more efficient and reliable than executing the step manually</li> <li>These are general software development tools that will give us a strategic advantage over our competitors</li> <li>A build and automation server is particularly useful if:<ul> <li>You are managing multiple projects<ul> <li>The automation server will update all interested parties via email / Teams</li> <li>The build server will automatically generate the PIP in a consistent environment, which makes machine updates easier because only the changes will get transferred to the target</li> </ul> </li> <li>The application has unit tests<ul> <li>The automation server will run them automatically and more frequently</li> <li>The build/automation server will allow for a clean slate testing environment</li> <li>The build server triggers all tests, so you have confidence that your code changes don\u2019t impact other aspects of the code</li> </ul> </li> </ul> </li> </ul>"},{"location":"AutomationBuildServer_0_TemplateFiles/","title":"Template Files","text":"<p>The only template file provided for this topic is a template Jenkinsfile. Further explanation on how to edit this Jenkinsfile according to your situation is provided later on.</p> <p></p>"},{"location":"AutomationBuildServer_1_HowToUseJenkins/","title":"How to use Jenkins","text":""},{"location":"AutomationBuildServer_1_HowToUseJenkins/#jenkins","title":"Jenkins","text":"<p>Jenkins is a very popular, open-source tool which provides deployment pipeline functionality. It can be used to automate all sorts of tasks related to building, testing, delivering and deploying software.</p> <p>This is the tool that B&amp;R uses for our automation server, so the rest of this PPT will be focused on Jenkins. You are free to investigate other options as desired.</p> <p></p>"},{"location":"AutomationBuildServer_1_HowToUseJenkins/#atl-jenkins-server","title":"ATL Jenkins Server","text":"<p>B&amp;R North America has a build/automation server running out of our ATL office that you can utilize as long as B&amp;R engineers are involved in your project and have credentials to your source control repository.</p> <ul> <li>This is convenient because it means you don\u2019t have to build up your own server right away</li> <li>To get started with this option, contact your B&amp;R NA representative. Note that this option is not available outside of North America</li> </ul> <p>Once B&amp;R is no longer actively involved in the project, though, you will need to create your own build/automation server setup.</p> <ul> <li>B&amp;R does not manage customer automation servers long-term</li> </ul> <p>Alternatively, you can create your own automation server setup from the get-go.</p>"},{"location":"AutomationBuildServer_1_HowToUseJenkins/#multibranch-pipeline","title":"Multibranch Pipeline","text":"<p>There are a few different project types within Jenkins, but the one we recommend is the Multibranch Pipeline.</p> <ul> <li>A pipeline is a workflow defined in text-based code within a text file called \u201cJenkinsfile\u201d</li> <li>A Multibranch Pipeline project automatically creates sub-projects for every branch in the source code repository<ul> <li>If a new branch is created and pushed to the repository, then a new sub-project in the multibranch pipeline is created and runs for that branch</li> </ul> </li> <li>The Jenkinsfile is committed to the source control repository, so the pipeline itself is protected by version control<ul> <li>This also means that the developers can freely/directly add steps to the pipeline</li> </ul> </li> </ul>"},{"location":"AutomationBuildServer_1_HowToUseJenkins/#multiple-multibranch-pipelines","title":"Multiple Multibranch Pipelines","text":"<ul> <li>You can configure multiple Jenkins pipelines to run in series.<ul> <li>Once the first pipeline completes successfully, the next one automatically starts running, and so on.</li> <li>Alternatively, since the pipelines are separated, you can run the integration tests (which typically take longer) at a lower frequency than the unit tests. The unit tests could run every time code is committed and pushed, but the integration test run only every 4 hours, for example.</li> </ul> </li> <li>We recommend using at least the following 3 distinct multibranch pipelines for AS project development:<ul> <li>Multibranch pipeline 1: Builds the project and runs unit tests</li> <li>Multibranch pipeline 2: Runs integration tests</li> <li>Multibranch pipeline 3: Handles the release deployment</li> </ul> </li> <li>Note: the template Jenkinsfile in this DevOps package is a starter implementation that corresponds to one single pipeline for building the project, running unit tests, and release deployment. Integration testing is not yet included (this will come in a future update to the DevOps package).</li> </ul>"},{"location":"AutomationBuildServer_2_BnRJenkinsHelperLib/","title":"B&amp;R-Jenkins Helper Library","text":""},{"location":"AutomationBuildServer_2_BnRJenkinsHelperLib/#readymade-groovy-scripts","title":"Readymade Groovy Scripts","text":"<ul> <li>B&amp;R North America has written a helper library that includes a lot of useful functions for interacting with AS projects</li> <li>The library contains Groovy scripts, which are wrappers around Python scripts and general commands</li> <li>You don\u2019t need to edit this library at all, but you will be using it in your Jenkinsfile<ul> <li>The functions are described on the next slides as an FYI</li> </ul> </li> <li>Public link to the library on GitHub<ul> <li>The Groovy scripts are located within the \u201cvars\u201d folder on the repo</li> <li>The Python scripts that the Groovy scripts utilize are located within the \u201cresources\\scripts\u201d folder on the repo</li> <li>Additional documentation can be found here</li> </ul> </li> <li>These scripts have been tested in AS4.7 and above. Prior AS versions may work, but they are currently untested.</li> </ul>"},{"location":"AutomationBuildServer_2_BnRJenkinsHelperLib/#add-to-jenkins-server","title":"Add to Jenkins Server","text":"<p>To utilize this helper library on your Jenkins server, do the following:</p> <ol> <li>Go to \u201cManage Jenkins\u201d</li> <li>Select \u201cSystem\u201d</li> <li>Scroll down to the \u201cGlobal Pipeline Libraries\u201d section. Click \u201cAdd\u201d. Then:<ul> <li>Fill out a Name for the library (whatever you prefer)</li> <li>In the \u201cDefault Version\u201d field, type \u201cmain\u201d</li> <li>Check the boxes for \u201cLoad implicitly\u201d, \u201cAllow default version to be overridden\u201d, and \u201cInclude @Library changes in job recent changes\u201d</li> <li>Set the Retrieval method to \u201cModern SCM\u201d</li> <li>Set \u201cSource Code Management\u201d to \u201cGitHub\u201d</li> <li>Fill out the credentials accordingly (or add new credentials if needed)</li> <li>In the \u201cRepository HTTPS URL\u201d field, paste this URL: https://github.com/br-automation-com/BnR-Jenkins-Helper-Library.git</li> <li>In the \u201cLibrary Path\u201d field, paste the following: ./</li> </ul> </li> </ol>"},{"location":"AutomationBuildServer_2_BnRJenkinsHelperLib/#workspace","title":"Workspace","text":"<p>The workspace is where Jenkins checks out the project from the repo and runs the pipeline.</p> <p>To reference the workspace in the Jenkinsfile, use the readymade environment variable \"${WORKSPACE}\"</p>"},{"location":"AutomationBuildServer_2_BnRJenkinsHelperLib/#version-info-functions","title":"Version Info Functions","text":"Function Description Arguments Version Returns full version number based on tag (e.g. 1.2.3.9004) workspace ReleaseVersion Returns Major.Minor.Bugfix style version number workspace MajorVersionNumber Returns just the Major version number workspace MinorVersionNumber Returns just the Minor version number workspace BugFixVersionNumber Returns just the bug version number workspace"},{"location":"AutomationBuildServer_2_BnRJenkinsHelperLib/#git-info-functions","title":"Git Info Functions","text":"Function Description Arguments BranchName Returns the name of the git branch workspace Tag Returns the last tag in the branch workspace IsReleaseCandidate Returns true if the branch is in the release/* branch workspace IsReleaseBranch Returns true if branch is master or main workspace"},{"location":"AutomationBuildServer_2_BnRJenkinsHelperLib/#ar-helper-functions","title":"AR Helper Functions","text":"Function Description Arguments BuildASProject Builds an Automation Studio Project project \u2013 path within the workspace to the project (the folder containing the .apj file). For example: \"$WORKSPACE\\TestProject\"configuration \u2013 configuration name in the AS projectmax_warnings \u2013 the maximum number or build warnings that are allowed in order to consider the build a success. Set this to -1 to accept infinite warningsbuildpip \u2013 whether to build the PIP or not BuildARsimStructure Creates the ARsim structure project \u2013 path within the workspace to the project (the folder containing the .apj file). For example: \"$WORKSPACE\\TestProject\"configuration \u2013 configuration name in the AS project"},{"location":"AutomationBuildServer_2_BnRJenkinsHelperLib/#unit-test-functions","title":"Unit Test Functions","text":"Function Description Arguments RunArUnitTests Runs unit test configuration in ArSim tests \u2013 the name of the unit tests to run. Use \u201call\u201d to run all testsconfiguration \u2013 configuration name in the AS project that contains the unit testsproject \u2013 path within the workspace to the project (the folder containing the .apj file). For example: \"$WORKSPACE\\TestProject\u201c ProcessArTestResults Process test results xml files N/A"},{"location":"AutomationBuildServer_2_BnRJenkinsHelperLib/#information-sharing-functions","title":"Information Sharing Functions","text":"Function Description Arguments UploadToGitHub Uploads build artifacts to a GitHub repository version \u2013 version number of the artifactorganization \u2013 repo organization namename \u2013 repo namefile \u2013 filename of the artifact to upload SendNotifications Sends an email to team members buildStatus \u2013 the status/result of the most recent build of the pipelinerecipients \u2013 list of email addresses to send the email to"},{"location":"AutomationBuildServer_3_GettingStarted/","title":"Getting Started","text":"<p>If you are utilizing the B&amp;R Jenkins server initially, then you can skip the steps shown here. </p>"},{"location":"AutomationBuildServer_3_GettingStarted/#system-requirements","title":"System Requirements","text":"<p>If you are setting up your own build/automation server, note the following system requirements:</p> <ul> <li>Hardware requirements<ul> <li>12 GB of RAM</li> <li>10 GB of drive space (&gt;50 GB recommended)</li> </ul> </li> <li>Software requirements<ul> <li>Windows 10</li> <li>Automation Studio 4.7 or above (version must match the project)<ul> <li>Plus all required upgrades for the project (manually installed on server)</li> <li>Note: supporting scripts have been tested in AS4.7 and above. Prior versions may work, but have not been checked</li> </ul> </li> <li>Python \u2265 3.9</li> <li>Required for automated build scripts</li> <li>Jenkins</li> <li>Java Development Kit</li> </ul> </li> </ul>"},{"location":"AutomationBuildServer_3_GettingStarted/#downloads-and-installation","title":"Downloads and Installation","text":"<p>Build and Automation Server</p> <ul> <li>Jenkins Download</li> <li>Java Development Kit Download</li> <li>Python Download</li> <li>Installation instructions for Jenkins and the JDK are located here.<ul> <li>Please review the video for full instructions on how to install the JDK, Jenkins, and make assorted configuration changes after install.</li> </ul> </li> <li>We recommend installing Jenkins on a server or dedicated PC</li> <li>We recommend installing Jenkins with the \u201crecommended plugins\u201d option<ul> <li>And manually add the \u201cOffice 365 Connector\u201d plugin</li> <li>Configure Extended E-mail Notification plugin</li> <li>Manually add the \"Coverage\" plugin</li> </ul> </li> <li>Python requirements<ul> <li> <p><pre><code>    C:\\&gt;pip install requests junitparser GitPython requests junitparser pytest pytest-order asyncua opcua selenium gcov\n</code></pre> </p> </li> </ul> </li> </ul>"},{"location":"AutomationBuildServer_4_CreateDocker/","title":"Creating Jenkins Agent Docker Container","text":""},{"location":"AutomationBuildServer_4_CreateDocker/#jenkins-agent","title":"Jenkins Agent","text":"<p>Create a new node to run the Jenkins agent.</p> <p>Goto \"Manage Jenkins\":</p> <p></p> <p></p> <p>Select \"Nodes\" under the System Configuration</p> <p></p> <p>Click the \"New Node\" button:</p> <p></p> <p></p> <p>Define the name of your node and select \"Permanent Agent\". Click \"Create\". </p> <p></p> <p></p> <p>Define \u201cRemote root directory\u201d:</p> <p></p> <p></p> <p>Define labels based on Automation Studio Version:</p> <p></p> <p></p> <p>Change \u201cUsage\u201d to \u201cOnly build jobs with label expressions matching this mode\u201d:</p> <p></p> <p></p> <p>Change \u201cLaunch method\u201d to \u201cLaunch agent by connecting it to the controller\u201d, check \u201cUse WebSocket\u201d, and click \"Save\":</p> <p></p> <p></p> <p>Copy the secret provided:</p> <p></p> <p></p>"},{"location":"AutomationBuildServer_4_CreateDocker/#docker-build","title":"Docker Build","text":"<p>Create a Docker container for the agent.</p> <p>Open the Dockerfile in a text editor:</p> <p></p> <p></p> <p>Adjust the JENKINS_URL for your configuration:</p> <p></p> <p></p> <p>Add the Jenkins secret from the node creation to JENKINS_SECRET, and adjust the JENKINS_AGENT_NAME with the name of the node:</p> <p></p> <p></p> <p>Copy any required Automation Studio upgrade files to the AS_Upgrades directory</p> <p>For any 3rd party hardware files copy them to the AS_3rd_Party_Files.  These can be copied from you local installation folder (e.g. C:\\ProgramData\\BR\\AS412\\Hardware)</p> <p>Create the Docker image:</p> <pre><code>C:\\&gt;docker build -t as_412 -f .\\Dockerfile .\n</code></pre> <p>Deploy the Docker container</p> <pre><code>C:\\&gt;docker create --name AS_412 --restart unless-stopped -v \"C:\\Program Files\\Jenkins\\jobs:C:\\Program Files\\jenkins\\jobs\" -v \"C:\\workspace:C:\\jenkins\\workspace\" -v \"C:\\Jenkins Setup\\docker\\upgrades\\additional_upgrades:C:\\additional_upgrades\" as_412 \n</code></pre>"},{"location":"AutomationBuildServer_5_CreateJenkinsProject/","title":"Create Jenkins project","text":"<p>Note: If you are utilizing the B&amp;R Jenkins server initially, then you can skip the steps in this section.</p>"},{"location":"AutomationBuildServer_5_CreateJenkinsProject/#create-a-multibranch-pipeline","title":"Create a Multibranch Pipeline","text":"<ol> <li>Open the Jenkins server web browser</li> <li>From the Dashboard, click \u201cNew Item\u201d in the top left and select \u201cMultibranch Pipeline\u201d</li> <li>Fill out the configuration for this new pipeline. Required changes:<ul> <li>Add a Branch Source<ul> <li>Fill out the corresponding fields, which vary depending on the source type</li> </ul> </li> <li>Set the Build Configuration Mode to \u201cby Jenkinsfile\u201d and update the script path to where you want this file to live in your repo<ul> <li>This file is where you will define your pipeline</li> </ul> </li> <li>Add the \u201cClean before checkout\u201d option to the repository</li> </ul> </li> <li>Paste the provided template \u201cJenkinsfile\u201d to the location you specified in step 3b</li> <li>Open the \u201cJenkinsfile\u201d in a text editor</li> </ol>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/","title":"Customizing the Jenkinsfile","text":""},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#overview-of-the-jenkinsfile-template","title":"Overview of the Jenkinsfile Template","text":"<p>The provided Jenkinsfile template accomplishes the following tasks:</p> <ol> <li>Builds the AS project</li> <li>Runs the unit tests</li> <li>Creates an ARsim structure and PIP</li> <li>Uploads the ARsim structure and PIP to GitHub, and sends them to an MS Teams channel via a chat message</li> <li>Sends an email with the results of the build</li> </ol> <p>This template is a starting point for your pipeline definition. There are a few things in this file that must be adjusted for it to run properly for your system.</p> <p>The following information identifies the purpose of each section in the Jenkinsfile and any changes you must make. </p> <p>There are 6 main sections in the Jenkinsfile pipeline:</p> <ul> <li>Variable Definitions  \u2013 Defines global variables</li> <li>Agent  \u2013 Defines where the pipeline will run within the Jenkins environment</li> <li>Environment  \u2013 Defines global environment variables</li> <li>Options  \u2013 Configures options</li> <li>Stages  \u2013 Defines the steps in the pipeline. If a stage fails, subsequent stages don\u2019t run</li> <li>Post  \u2013 Always runs at the end of the pipeline, even if a stage fails</li> </ul>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#difference-between-variables-and-environment-variables","title":"Difference between Variables and Environment Variables","text":"<p>Variables:</p> <ul> <li>Defined outside the pipeline, at the top of the file</li> <li>All variables are global</li> </ul> <p>Environment Variables:</p> <ul> <li>Defined within an environment{} section, either at the top level of the pipeline (for pipeline global environment variable declarations) or within a stage of the pipeline (for stage local declarations)</li> <li>Global environment variables can also be defined in the configuration of Jenkins. In this case, the variables are accessible to all pipelines</li> <li>There are also some built-in environment variables that can be used throughout any Jenkinsfile (analogous to System Variables in mapp View). A full list of predefined and readily available environment variables in Jenkins is available here.</li> <li>The built-in workspace environment variable (${WORKSPACE}) is not available until the pipeline starts running. Therefore, if the variable you are creating needs to reference the workspace, you must declare it as an environment variable. In our template file, this is why PROJECT_DIR and RELEASE_VERSION are declared as environment variables.</li> </ul>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#customization","title":"Customization","text":""},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#variables","title":"Variables","text":"<p>Starting at the top of the Jenkinsfile, we will begin by adjusting the global variables. The following table describes each variable. Adjust the values accordingly:</p> Variable Name Description TEAMS_CHANNEL_URL Teams channel webhook URL where messages about the pipeline status will automatically be sent. For more details on how to define this, refer to the \u201cOptions\u201d section. CONFIG_NAME Name of the configuration in the AS project that you are running through the pipeline UNIT_TEST_CONFIG_NAME Name of the unit test configuration in the AS project REPO_NAME Name of the GitHub repository. Only required if you plan to upload files to GitHub. REPO_ORGANIZATION Name of the GitHub organization. Only required if you plan to upload files to GitHub. EMAIL_LIST List of email addresses that you want to send the results to, each separated by a semicolon"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#agent","title":"Agent","text":"<p>Edit the \u201cagent\u201d line:</p> <ul> <li>If you are utilizing the B&amp;R Jenkins server to start, then identify the docker container your pipeline will run in. This simply depends on the AS version of your project<ul> <li>Example: AS_412</li> </ul> </li> <li>If you have built your own Jenkins server, then specify the agent accordingly.</li> </ul> <p></p>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#environment","title":"Environment","text":"<p>The following table describes each environment variable. Adjust the values accordingly:</p> Variable Name Description PROJECT_DIR Specify the path within the repository to the AS project (the folder containing the .apj file). Use \\\\ for folder separation.Example: PROJECT_DIR = \"$WORKSPACE\\\\TestProject\u201cIf the project is stored in the root directory, then leave it defined as PROJECT_DIR = \"$WORKSPACE\" RELEASE_VERSION Holds the version number of the code in the repo. No changes required."},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#options","title":"Options","text":"<p>The \u201coptions\u201d section sets up a webhook to an MS Teams channel so that you can automatically send information to that channel. This includes: * Updates on when the pipeline has started / stopped * Whether the pipeline succeeded * The output files of the pipeline (by default in our template, the output files are the zipped up ARsim structure and PIP)</p> <p>To establish this connection, you need to obtain your Teams channel webhook URL (see next section) and paste it in the value for the TEAMS_CHANNEL_URL variable</p> <p></p>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#obtaining-the-webhook-url","title":"Obtaining the Webhook URL","text":"<p>To obtain the webhook URL for a Microsoft Teams Connection, follow these steps: </p> <ul> <li> <p>Navigate to the channel in the Team that you want to establish the connection to</p> </li> <li> <p>Click the \u201c\u2026\u201d button, then click \"Connectors\"</p> </li> </ul> <p></p> <ul> <li>Click \u201cConfigure\u201d for \u201cIncoming Webhook\u201d</li> </ul> <p></p> <ul> <li>Give your webhook a name and click \u201cCreate\u201d</li> </ul> <p></p> <ul> <li>Afterwards, the URL you need will be populated in the field at the bottom. Copy this link and paste it at the top of the Jenkinsfile as the value of the TEAMS_CHANNEL_URL variable</li> </ul> <p></p>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#stages","title":"Stages","text":"<p>The next section in the pipeline is the stages. This is where you define the actions that the build server will perform. This is the \u201cmeat and potatoes\u201d of the pipeline.</p> <p>There are 4 stages set up in the template Jenkinsfile, which we will now go through one by one:</p> <ol> <li>Update Tags</li> <li>Build AS Project</li> <li>Unit Tests</li> <li>Deploy</li> </ol>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#stage-update-tags","title":"Stage: Update Tags","text":"<ul> <li>This stage force-pulls the tags in the repository</li> <li>Note that therefore, at least one tag must exist in the repo</li> <li>This information will be used later to create a version number</li> <li>No changes necessary</li> </ul>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#stage-build-as-project","title":"Stage: Build AS Project","text":"<ul> <li>This stage builds the AS project</li> <li>A value of -1 for \u201cmax_warnings\u201d means you can have infinite warnings. If you optionally specify a positive value here, the stage will fail if the number of build warnings exceeds this value.</li> </ul>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#stage-unit-tests","title":"Stage: Unit Tests","text":"<ul> <li> <p>This stage runs the automated unit tests</p> </li> <li> <p>If the pipeline gets stuck on a unit test for longer than 15 minutes, the tests will fail. Optionally adjust this timeout value as desired.</p> </li> </ul> <p></p>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#stage-deploy","title":"Stage: Deploy","text":"<ul> <li> <p>The template separates the deploy stage between release branches and feature/develop branches</p> </li> <li> <p>Therefore, you can trigger different actions depending on what branch you pushed to</p> </li> <li> <p>By default, both stages create the ARsim structure and Project Installation Package</p> </li> <li> <p>If you want to perform another action in either stage, add it accordingly</p> </li> </ul> <p></p>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#post","title":"Post","text":"<p>The code within Post will always run, even if a stage in the pipeline fails.</p> <p>Within Post, there are 3 subsections:</p> <ol> <li>Always  \u2013 runs in every single post processing</li> <li>Success  \u2013 runs if all unit tests pass</li> <li>Unstable  \u2013 runs if any of the unit tests fail. This is classified as \u201cunstable\u201d rather than a failure because the pipeline itself completed, but the tests did not pass.</li> </ol>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#post-always","title":"Post: Always","text":"<p>The \u201cAlways\u201d post script converts the B&amp;R Unit test results into a data format that Jenkins can understand what passed/failed.</p> <p>It archives the ARsim structure and PIP so that they can be used in subsequent pipelines or uploaded to GitHub/Teams.</p> <p>It als osends an email with the build status to the EMAIL_LIST recipients.</p> <p>The PIP that gets automatically generated uses the following installation settings:</p> <ul> <li>Consistent installation</li> <li>Allow updates without data loss</li> <li>Keep PV values</li> <li>Ignore version</li> <li>Always install</li> </ul>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#example-of-a-successful-build-email-notification","title":"Example of a Successful Build Email Notification","text":"<p>All Tests Passed</p> <p> </p>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#example-of-an-unstable-build-email-notification","title":"Example of an Unstable Build Email Notification","text":"<p>Some Tests Failed</p> <p> </p>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#post-success-unstable","title":"Post: Success, Unstable","text":"<p>Both the \u201cSuccess\u201d and \u201cUnstable\u201d post scripts do the following:</p> <ul> <li>Upload the artifacts to GitHub</li> <li>Send a message to the Teams channel with the status and artifact download links</li> </ul> <p>The only differences between these post scripts are:</p> <ul> <li>The color scheme (green for success, yellow for unstable)</li> <li>The text that gets used for the Teams message (\u201cBuild Success\u201d vs \u201cBuild Unstable\u201d).</li> </ul>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#example-of-ms-teams-messages","title":"Example of MS Teams Messages","text":"<p>Success: </p> <p></p> <p>Unstable:</p> <p></p>"},{"location":"AutomationBuildServer_6_CustomizingTheJenkinsfile/#post-success-unstable_1","title":"Post: Success, Unstable","text":"<p>Required steps:</p> <ul> <li>Comment/uncomment the upload lines depending on whether you want to upload the artifacts to GitHub</li> <li>If you do choose to upload, make sure you have edited the REPO_NAME and REPO_ORGANIZATION variables at the top of the Jenkinsfile accordingly</li> </ul> <p></p>"},{"location":"AutomationBuildServer_7_IntegrationWithBitbucket/","title":"Integration with Bitbucket","text":"<p>To integrate Jenkins with Bitbucket, follow these steps. </p> <p>From the Bitbucket project, click on your user icon and select \u201cManage account\u201d:</p> <p></p> <p>Select \u201cHTTP access token\u201d in the menu on the left. Then click \"Create token\":</p> <p></p> <p>Add a token name. Set the Permissions to \u201cRepository read\u201d. Click \u201cCreate\u201d:</p> <p></p> <p>Make sure to copy the generated token as you will not be able view this again.</p> <p></p> <p>Create new project in Jenkins. Enter name of project. Select multibranch pipeline:</p> <p></p> <p>Add source - select Bitbucket: </p> <p></p> <p>Add Credential - select project name:</p> <p></p> <p>Change \u201cKind\u201d to \u201cUsername with password\u201d. Paste the HTTP access token created from Bitbucket. Give unique ID:</p> <p></p> <p>Select new Credential. Set the \u201cOwner\u201d to the Bitbucket project key (4 letter identifier). Once the Owner is entered, the Repository Name should show up in list:</p> <p></p> <p>Then Add \u201cAdvanced clone behaviors\u201d, and ensure that \u201cFetch tags\u201d is checked:</p> <p></p> <p></p> <p>After saving, the repositories will be scanned:</p> <p></p>"},{"location":"AutomationBuildServer_8_AutomatedDeployment/","title":"Automated Deployment","text":"<p>Recommendations on automated deployment will be added in a future revision of the B&amp;R DevOps package.</p> <p>For an immediate solution, consider Shuv. Shuv handles many aspects of the CI/CD process for you, in addition to automated deployment.</p> <p></p> <p>Shuv handles the following processes: </p> <ul> <li>Manages CI/CD pipelines for your Automation Studio projects and B&amp;R PLCs</li> <li>Automated pipelines trigger on Git events</li> <li>Builds simulator and physical PIPs</li> <li>Runs unit tests and integration tests against the simulator</li> <li>Integrates with Git to keep track of code versions</li> <li>Delivers OTA software updates to PLCs that are connected to Shuv via MQTTS</li> </ul> <p></p> <p>Note that there is a cost to use Shuv (it is not free). </p>"},{"location":"ProjectManagement/","title":"Project Management","text":""},{"location":"ProjectManagement/#agile-workflow","title":"Agile Workflow","text":"<p>This article provides a thorough overview of Agile project management, and how it compares to the traditional waterfall approach. Agile strategies are recommended. </p>"},{"location":"ProjectManagement/#project-management-topics","title":"Project Management Topics","text":"<p>For effective project management, the following topics must be addressed:</p> <ul> <li>Content Collaboration \u2013 to store information</li> <li>Issue Tracking \u2013 to manage tasks</li> <li>Hosting Service \u2013 to manage Git repositories</li> </ul> <p>The subsequent resources identify the tools we use at B&amp;R, which will therefore be referenced throughout the rest of the DevOps package.</p>"},{"location":"ProjectManagement/#content-collaboration","title":"Content Collaboration","text":"<p>A content collaboration tool is needed to store information such as meeting notes, brainstorming, project planning, documentation, etc.</p> <p>At B&amp;R, we use Confluence. Alternate options that you can also consider include Microsoft Sharepoint, Notion, Guru, Stack Overflow for Teams, and so on.</p> <p></p>"},{"location":"ProjectManagement/#issue-tracking","title":"Issue Tracking","text":"<p>An issue tracking system is needed to manage the tasks associated with a project via the agile workflow.</p> <p>At B&amp;R, we use Jira. Alternate options that you can consider include Asana, monday.com, Microsoft Azure Boards, and so on.</p> <p></p>"},{"location":"ProjectManagement/#hosting-service","title":"Hosting Service","text":"<p>A hosting services is needed to manage your Git repositories.</p> <p>At B&amp;R, we use Bitbucket and GitHub. Alternate options that you can consider include Microsoft Azure Repos, GitLab, Amazon AWS CodeCommit, and so on.</p> <p></p>"},{"location":"ProjectManagement_0_ProjectPlanning/","title":"Project Planning","text":""},{"location":"ProjectManagement_0_ProjectPlanning/#define-personnel-resources","title":"Define Personnel Resources","text":"<p>Prior to software development, identify the individuals that will be responsible for various roles. The following list describes the baseline/minimum roles that must be defined. Additional roles may be required depending on the application complexity. Note that one person can hold more than one role.</p> Role Description Project Manager Responsible for the successful execution the project. Primary decision maker. Handles project version definition. Application Architect Responsible for designing the application. Typically, a senior engineer. Engineer Responsible for developing the application. Can be any engineer. Test Manager* Defines the tests Test Developer* Writes the automated tests Manual Tester* Executes the manual tests. Does not analyze the results of any subjective tests (if applicable) Manual Test Approver* Analyzes the outcome of the subjective manual tests (if applicable) <p>* Refer to the Testing section </p>"},{"location":"ProjectManagement_0_ProjectPlanning/#project-overview-diagram","title":"Project Overview Diagram","text":"<p>Prior to any software development, create a  block diagram / class diagram / flow chart that represents each control element of the machine. This should be created in tandem with the machine specification. </p> <p>Once you have this diagram, each block will become an epic within your Jira project.</p> <p>Then the more granular requirements for that control element will become stories, tasks and bugs within that epic.</p> <p>For example: </p> <p></p>"},{"location":"ProjectManagement_0_ProjectPlanning/#code-design-testing","title":"Code Design &amp; Testing","text":"<p>As you dive further into the details of the code design, be thinking about how you are going to test the code while you are designing it (and before you start writing it).</p> <p>The process of writing your unit tests will become easier if you keep them in mind from the get-go.</p> <p>Refer to the Testing section of this DevOps package for further details.</p> <p></p>"},{"location":"ProjectManagement_1_Jira/","title":"Jira","text":""},{"location":"ProjectManagement_1_Jira/#issues","title":"Issues","text":""},{"location":"ProjectManagement_1_Jira/#terminology","title":"Terminology","text":"<p>Every work item within Jira is generically referred to as an \"Issue\".  This applies to things like bugs / tasks, as well as projects as a whole. Therefore, don\u2019t be concerned if you attempt to create a Project, for example, but the dialog says \"Create Issue\".</p> <p></p>"},{"location":"ProjectManagement_1_Jira/#jira-issue-hierarchy","title":"Jira Issue Hierarchy","text":"<p>The following graphic summarizes the hierarchy of issues within Jira.</p> <p>At the top level you have either a Project or a Service Project.</p> <p></p>"},{"location":"ProjectManagement_1_Jira/#jira-issue-types","title":"Jira Issue Types","text":"<p>The following five issue types are used to define all work within a project:</p> Epic Story Task Sub-Task Bug Symbol Description \u2022 Feature / module, or high-level requirement  \u2022 Large chunk of work  \u2022 Can broken down into smaller pieces \u2022 Piece of work within an epic  \u2022 Has a clear, defined value to the end user \u2022 Piece of work within an epic  \u2022 Does not directly bring value to the end user  \u2022 Does not require specification or review \u2022 Piece of work within a story, task or bug  \u2022 Used to divide a story into specific chunks \u2022 Problem that impacts or prevents the function of a feature  \u2022 Unwanted or unexpected behavior Examples \u2022 HMI  \u2022 Module  \u2022 Station \u2022 Communication program  \u2022 Alarms page  \u2022 Trak process point code \u2022 Set up Hypervisor  \u2022 Set up an SQL database \u2022  Add alarms to task \u2022  Page fault  \u2022 mapp View button not working"},{"location":"ProjectManagement_1_Jira/#create-an-issue","title":"Create an Issue","text":"<p>To create a story, task, bug, or epic, do the following:</p> <ol> <li>Open the project in Jira</li> <li>Click the \u201cCreate\u201d button at the top</li> <li>Select the proper issue type from the \u201cIssue Type\u201d dropdown</li> <li>Fill out the rest of the form accordingly</li> </ol> <p>The newly created issue will then be sent to your backlog.</p> <p></p> <p>To create a sub-task, the workflow is slightly different. In this case: </p> <ol> <li>Open up the issue that you want to create a sub-task under</li> <li>Go to \"More\" \u2192 \"Create sub-task\"</li> <li>Fill out the fields accordingly</li> </ol> <p></p>"},{"location":"ProjectManagement_1_Jira/#changing-the-issue-type","title":"Changing the Issue Type","text":"<p>If you created a new Jira issue but accidentally created it with the wrong type, you can adjust it after the fact as follows:</p> <ol> <li>Navigate to the Jira issue</li> <li>Go to \"More\" \u2192 \"Move\"</li> <li>Change the \"Current Issue Type\" dropdown to the intended issue type</li> <li>Click Next and follow the subsequent prompts (which vary depending on the new issue type)</li> </ol> <p></p>"},{"location":"ProjectManagement_1_Jira/#project-topics","title":"Project Topics","text":""},{"location":"ProjectManagement_1_Jira/#jira-project-pages","title":"Jira Project Pages","text":"<p>The following pages are available in every Jira project:</p> Page Description Backlog Displays all open issues which are currently being worked on, as well as all issues that are waiting to be assigned in the future Active sprints / Kanban board Displays the current sprint or the Kanban board, depending on which board is currently selected via the dropdown right above the Backlog page Releases Allows you to define release versions, which can then be assigned to each Jira issue. Big-picture deadlines for development. Allows you to see a progress bar for how far along you are in a particular release. Reports Allows you to view the status and progress of the whole project. Issues Lists out all issues within the project. Can be filtered. Components Similar to releases, but for topics rather than a point in time / due date. Useful for collecting all issues related to one topic, even if they span multiple epics (e.g. all motion issues). Timesheets Allows you to see time logged to the project by the various contributors Structure Allows you to create customizable filters for project analysis Objects Currently unused at B&amp;R <p></p>"},{"location":"ProjectManagement_1_Jira/#components-vs-epics","title":"Components vs Epics","text":"<p>Comparison</p> <p>Components and Epics are quite similar in that they are higher level containers for Jira issues. However, there are some key differences:</p> Components Epics Duration Exists for the duration of the project Intended to be completed and closed out within a shorter time frame than the project as a whole. (Can also remain open for the whole project, but generally intended to be completed at some point) Intended use Topic related. Issues that belong to one component can be spread out across multiple epics Intended for a specific feature or module of the machine Quantity Multiple components can be assigned to each issue Only one epic can be assigned to each issue Time tracking No requirement Every Jira issue must be assigned to an Epic for time tracking to function properly Filter capability Has a dedicated page within the Jira project sidebar which makes it easy to select a component and view all corresponding issues. You can also see all issues assigned to a component by using the \u201cComponent\u201d filter option in the issue filter See all issues assigned to an epic by using the \u201cEpic Link\u201d filter option in the issue filter"},{"location":"ProjectManagement_1_Jira/#releases","title":"Releases","text":"<p>Release versions allow you to define a software version and then assign Jira issues to that version (via the \"Fix Version\" field in the issue details).</p> <p></p> <p>While the release is in progress, you get a progress bar showing how far along you are in completing all of the things assigned to that release.</p> <p></p> <p>Once you complete a release, you can view all issues related to the release as well as a full list of built-in release notes.</p> <p></p>"},{"location":"ProjectManagement_1_Jira/#boards","title":"Boards","text":""},{"location":"ProjectManagement_1_Jira/#kanban-and-sprint","title":"Kanban and Sprint","text":"<p>There are two types of boards in a Jira project:</p> <ol> <li>Kanban<ul> <li>Define different workflow stages (e.g. To Do, In Progress, Done) as columns (aka swimlanes) and move each Jira issue through the process as it\u2019s being worked on</li> <li>Issues are organized by epic</li> </ul> </li> <li>Scrum/Sprint<ul> <li>Similar to Kanban, but limits your scope of work to only the tasks within the active sprint</li> <li>Sprints are short periods of time (typically about 2 weeks) that are essentially short-term goals for progress on the overall project</li> <li>Assign/plan work that is achievable to complete in that time frame, and then focus exclusively on those tasks. Planning out the work in short intervals like this helps you to make continual progress on a project, rather than inadvertently waiting until close to the deadline to try to cram everything in</li> <li>We highly recommend the use of sprints, as they are an invaluable time management tool</li> </ul> </li> </ol>"},{"location":"ProjectManagement_1_Jira/#how-to-create-boards","title":"How to Create Boards","text":"<p>Create a new board via the dropdown at the top of the sidebar:</p> <p></p> <p>You will then have the option to create either a scrum board or Kanban board:</p> <p></p>"},{"location":"ProjectManagement_1_Jira/#how-to-configure-boards","title":"How to Configure Boards","text":"<p>Configure the board via the \"Board\" dropdown on the right side. </p> <p></p> <p>This is where you define your columns and what issue statuses belong in each column. The column definition is up to your personal preference. If you have no strong preference, then we recommend the following setup:</p> <p></p>"},{"location":"ProjectManagement_2_Confluence/","title":"Confluence","text":""},{"location":"ProjectManagement_2_Confluence/#what-information-should-you-store","title":"What Information Should You Store?","text":"<p>Confluence is used to store project information such as:</p> <ul> <li>Big picture timelines</li> <li>Personnel lists</li> <li>Summary of Jira issues (via a macro \u2013 not manually entered)</li> <li>Application spec</li> <li>Meeting notes</li> <li>etc</li> </ul> <p>Confluence is quite flexible in that you can add new pages and sections as you see fit.</p> <p>Take care of project permissions!</p>"},{"location":"ProjectManagement_2_Confluence/#confluence-space-template","title":"Confluence Space Template","text":"<p>Various Confluence project templates are available to help you organize your project.</p> <p>You can also create your own template to be reused within your organization.</p> <p>At B&amp;R, our default template includes the pages shown below:</p> Template Page Description Organizational Contains buttons for easily creating meeting notes.Contains summary lists of all open Jira issues and Confluence tasks. Requirements Allows you to input the project specification as individual requirement pages Application For storing a .zip copy of the project (optional \u2013 should use source control instead) Project controlling For defining big-picture deadlines About For listing out the relevant personnel at the customer and at B&amp;R Userlist Lists out all people who have access to the Confluence space <p></p>"},{"location":"ProjectManagement_3_Bitbucket/","title":"GitHub &amp; Bitbucket","text":"<p>For details on GitHub and Bitbucket, refer to the Version Control section of this DevOps package. </p>"},{"location":"ProjectManagement_4_OpenSourceLicensing/","title":"Open-Source Licensing","text":""},{"location":"ProjectManagement_4_OpenSourceLicensing/#how-to-select-and-open-source-license","title":"How to Select and Open-Source License","text":"<p>If you are creating collaborative software that is intended to be shared and expanded upon (i.e. not a direct customer project), then you should include an open-source license with the code.</p> <p>The following resources are available to help you select an open-source license:</p> <ul> <li>The Legal Side of Open Source | Open Source Guides</li> <li>Licensing a repository - GitHub Docs</li> <li>Choose an open source license | Choose a License</li> </ul> <p>If you are unsure what license to select, then the MIT license is recommended.</p>"},{"location":"Testing/","title":"Testing","text":""},{"location":"Testing/#setting-the-stage","title":"Setting the Stage","text":"<p>Testing can either be  automated  or  manual. </p> <p>In DevOps, the goal is that you have as much automated testing as possible. Therefore, the primary focus of this package is automated testing. </p> <p>Nonetheless, some manual testing will inevitably be necessary. Therefore, manual testing strategies are provided at the end. </p>"},{"location":"Testing/#definition","title":"Definition","text":"<p>Automated testing begins with a defined test plan, comprised of required features and previously discovered bugs.  The test plan is the contract of what the software is expected to deliver.</p> <p>A consistent set of inputs is used for each test. This allows multiple programmers to execute the tests in the exact same way.</p> <p>The tests are run automatically - not by hand (manually) by each engineer. </p> <p>If a bug is discovered, a new test is written to catch the bug so that once it is fixed, you will always be checking to confirm it does not return in the future. </p>"},{"location":"Testing/#types-of-tests","title":"Types of Tests","text":""},{"location":"Testing/#benefits-of-automated-testing","title":"Benefits of Automated Testing","text":"Benefit Details Save time \u2022 Running automated tests is MUCH faster than manual testing.  \u2022 Bugs that are found later in development are more difficult and take longer to fix. Save money \u2022 Saving engineering time saves you money! Quality \u2022 End up with fewer bugs in production code (studies have shown between 40%-90% less bugs[source]!)\u2022 New tests are written for each new bug that is found. This ensures that future features/bugfixes don\u2019t break existing functionality.\u2022 Existing tests are repeatably executed with every release.\u2022 Encourages the design of more modular / testable code. Maintainability Increase the testability, readability, and adaptability of the code:\u2022 Testability: create thorough and reproducible tests\u2022 Readability: tests become a record of bugs and features. Makes it easier for other engineers to understand the code\u2022 Adaptability: promotes the creation of modular code"},{"location":"Testing/#addressing-the-arguments-against-automated-testing","title":"Addressing the Arguments Against Automated Testing","text":"Argument Counterargument Creating unit tests is too time consuming The result is higher quality software and less bugs in the field. The time you spend writing automated tests would end up being spent (and then some!) during manual testing anyway You can\u2019t write the test until you know the design If you don\u2019t know enough about the requirements to write a test, then you don\u2019t have enough information to write quality code. We must avoid the tendency to start coding before a proper plan is in place Unit testing is hard! It can be difficult at first, but like most things it gets easier the more you do it  \u2003\u2022 It is definitely difficult if you wait to add unit tests at the end (don\u2019t do that!) \u2003\u2022 This could also be an indication that your design is not easily testable (too much functionality in a single function / function block / task, etc) \u2003\u2022 Not everything is able to be unit tested. But in those cases, you will rely on manual testing I don\u2019t know how! Hence why this DevOps package exists!"},{"location":"Testing_0_TemplateFiles/","title":"Template Files","text":"<p>The following template files are included in the DevOps package:</p> <ul> <li>A template Excel file for keeping track of your tests</li> <li>A unit test getting started guide</li> <li>Examples of good and bad unit tests</li> </ul>"},{"location":"Testing_1_TestPlan/","title":"How to Build a Test Plan","text":""},{"location":"Testing_1_TestPlan/#overview","title":"Overview","text":"<p>The testing process begins with a solid and complete test plan that is closely linked to the project spec.</p> <p>The test plan must be thoughtfully written before testing and development begin. The requirements + project specification + test plan all go together. These should be completed before you write any code.</p> <p>In this section, we will identify recommendations for building such a test plan. The overall  steps are as follows:</p> <p></p>"},{"location":"Testing_1_TestPlan/#analyze-the-application","title":"Analyze the Application","text":"<p>The first step in building a test plan is to fully understand the application under test. Therefore, the specification must be written before you can create your test plan.</p> <ul> <li>For new projects, the base functionality must be defined</li> <li>For new features in an existing project, the details for that feature must be defined</li> </ul> <p>Remember: If the project has not been defined yet, then you cannot write reliable or quality code (not to mention, quality tests!)</p>"},{"location":"Testing_1_TestPlan/#design-the-test-strategy","title":"Design the Test Strategy","text":"<p>There are several things that must be defined in the overall test strategy:</p> <ol> <li>Testing Scope</li> <li>Testing Type</li> <li>Resource Planning</li> <li>Testing Schedule</li> </ol>"},{"location":"Testing_1_TestPlan/#testing-scope","title":"Testing Scope","text":"<p>Based on the project specification, define what will and will not be tested.</p>"},{"location":"Testing_1_TestPlan/#testing-type","title":"Testing Type","text":"<p>This DevOps package provides direct recommendations on unit testing, mapp View integration testing, and manual testing. </p> <p>Additional integration testing strategies will be added in the future.</p>"},{"location":"Testing_1_TestPlan/#resource-planning","title":"Resource Planning","text":"<p>Define at least one personnel resource for the following 4 testing roles. Note that one single person can hold multiple roles:</p> Role Description Test manager Defines the tests Test developer Writes the automated tests Manual tester Executes the manual tests. Does not analyze the results of any subjective tests (if applicable)Note: This should not be the programmer. Ideally should be an experience user of the machine under test Manual test approver Analyzes the outcome of the subjective manual tests (if applicable) <p>Then, define the test environments: </p> Test Environment Description / Action Items Automated test environment Refer to the Build Server section of this DevOps package On-machine testing \u2022 Identify the point of contact for scheduling machine time\u2022 Identify any materials and prerequisites needed for on-machine testing  \u2022 Estimate the time expected to complete the manual tests\u2022 Identify the testing location (OEM or end user)\u2022 Remember: manual testing is a distinct step from commissioning!"},{"location":"Testing_1_TestPlan/#testing-schedule","title":"Testing Schedule","text":"<p>Identify how often you will run the automated tests. Refer to the Build Server section of this DevOps package. </p> <p>Identify when and how often you will run the manual tests, first in simulation and then on machine.</p> <p>Plan a time to review all test results and define the next steps. </p>"},{"location":"Testing_1_TestPlan/#define-the-test-module-and-test-cases","title":"Define the Test Module and Test Cases","text":"<p>Definitions:</p> <ul> <li>A test module describes an overall functionality on the machine. This is used for organizing all of the test cases.</li> <li>A test case is a specific, granular test condition. Several test cases are used to fully test a test module.</li> </ul> <p>Examples:</p> <ul> <li>Test Module: Alarm System<ul> <li>Test Case 1: Confirm that the alarm history successfully exports</li> <li>Test Case 2: Confirm that the AlarmList widget on the HMI properly displays the alarms</li> <li>\u2026</li> </ul> </li> <li>Test Module: Recipe System<ul> <li>Test Case 1: Confirm you are warned / prompted if the default recipe is missing</li> <li>Test Case 2: Confirm that you can edit the active recipe and the changes are applied immediately</li> <li>\u2026</li> </ul> </li> </ul> <p>Directives:</p> <ul> <li>All test modules and corresponding test cases must be defined. This should be done within the testing template excel sheet that is provided in this DevOps package</li> <li>Identify whether each test case will be implemented with unit testing or manual testing</li> <li>Identify who has ownership of each test case </li> </ul> <p></p> <p>Below is a list of generic tests that should be applied to every machine. This list will continue to be expanded to over time.</p> <p>HMI</p> <ul> <li>All inputs should have proper limits (&gt;max and &lt;min are not permitted)</li> <li>Language changes accordingly as well as all the text fits in the given spaces in all languages</li> <li>Unit conversion functions</li> <li>Confirm that inputs are locked out for users that don't have access. Part of the manual tests.</li> <li>Confirm the alarm list is visible / working properly, and that alarms are acknowledgeable</li> <li>If HMI gets disconnected from the PLC (in hardware topologies where this is possible), test that recovery is possible, but also that commands don't happen unintendedly after disconnect (i.e. if you are manually jogging, disconnect, don't keep jogging indefinitely) (i.e. if you are in automatic mode, HMI disconnects, is it ok to continue?)</li> <li>Manually test for system responsiveness, if it is \"good enough\u201c</li> </ul> <p>Basic Motion</p> <ul> <li>E-stop, confirm it works</li> <li>Homing, confirm it works and it's repeatable</li> <li>Software limits (confirm the axis stops after reaching the limit)</li> <li>Hardware limits (confirm the axis stops after reaching the limit and before the hard stop)</li> <li>Jog, confirm it works</li> <li>Error conditions and recovery - examples: lag error, loss of comm from the PLC to the drive, etc. Will depend on the app, but think about these error conditions and confirm that you can successfully recover.</li> </ul> <p>IO</p> <ul> <li>Check that the ModuleOKs are monitored and that the response is as intended (just an alarm, stop the machine, service mode, etc)</li> <li>For any IO points that have a status feedback, make sure you're monitoring them and doing something with that information. The test here is regarding what you actually do with that status information. Confirm that the next step works.</li> <li>Fieldbuses- if disconnected, check you can recover, and that the machine responds in the way that you need it to.</li> </ul> <p>Data management</p> <ul> <li>Wear level monitoring info that came in AR4.9, make sure you are using that information and that the response is as intended.</li> <li>If your file device storage medium gets full, check that upon trying to save new data you are appropriately warned and that you don't lose any data</li> </ul>"},{"location":"Testing_1_TestPlan/#test-execution-and-reporting","title":"Test Execution and Reporting","text":"<p>Automated Tests</p> <ul> <li>The automation server executes the tests in ARsim and provides a report on the automated tests</li> <li>Refer to the Automation Server section of this DevOps package</li> </ul> <p>Manual Tests</p> <ul> <li>Manual tests are manually executed and reported</li> <li>Manual testing should be done only after the Automated Tests are in a good state (mostly or fully all passing)</li> <li>To help keep track of the status of the manual tests, there is a template Excel file provided in this package</li> <li>Details for how to use the file are included on the first tab (\u201cOverview\u201d)</li> <li>Be sure to identify the software version you are testing in the sheet, so that it is clear exactly what version you have tested</li> </ul> <p>At this step you must also define the overall test criteria for what constitutes pass/fail. At what point do you consider a feature or the machine as a whole \"done\"?</p> <p>It is indeed possible that a machine can ship with certain defects (failed tests). It is up to the project manager discretion whether a specific test is a show-stopper or not. Ask yourself: Is the cost of delaying shipment worth the defect?</p> <p>Execute all tests at least once. For each failed test, identify if the test case is a showstopper or not. This saves you from having to make this decision for every single test. In practice you only need to decide for tests that fail at any point. Alternatively, you can define a priority for each failed test. Then pick a cutoff point where the machine can ship despite defects.</p>"},{"location":"Testing_2_TDD/","title":"Test Driven Development","text":""},{"location":"Testing_2_TDD/#overview","title":"Overview","text":"<p>We will not only be focusing simply on automated unit tests themselves, but also on the Test Driven Development (TDD) workflow, which provides guidelines for when/how to write your tests.</p> <p></p> <p>The process is as follows: </p> <ol> <li> <p>Write the test</p> <ul> <li>In TDD, the test is written BEFORE the feature itself</li> </ul> </li> <li> <p>Run the test</p> <ul> <li>The test must fail because the feature has not been implemented yet</li> <li>If the test succeeds, re-work the test until it fails</li> </ul> </li> <li> <p>Write the code for the feature</p> <ul> <li>Afterwards, run the test. If the feature was implemented correctly, the test should pass</li> <li>If the test fails, re-work the feature until the test passes</li> </ul> </li> <li> <p>Run all tests, check if they succeed</p> </li> <li> <p>If all tests succeed, consider refactoring</p> <ul> <li>Now that you have identified what needs to be done in order to pass each test, you may realize a better way to accomplish a feature. Refactor accordingly.</li> <li>If some tests fail, correct the features and/or the tests themselves</li> </ul> </li> </ol> <p>Once this whole process is complete, return to the \u201cTest First\u201d development phase by writing the tests for the next features to be implemented (step 1).</p>"},{"location":"Testing_2_TDD/#what-to-test","title":"What to Test","text":"<ul> <li>Test the common / baseline functionality<ul> <li>This will tell you when the code breaks after you made a change (new feature / bugfix)</li> </ul> </li> <li>Test the edge cases of unusually complex code that you think could have potential errors<ul> <li>This is code that is likely to break when changes are made</li> </ul> </li> <li>Whenever you find a bug, write a new test case to cover it before fixing it<ul> <li>This ensures that you have correctly identified how to reproduce the bug and that your fix is correct</li> <li>It also ensures that you will catch it if the bug returns due to a code change in the future</li> </ul> </li> <li>Add edge case tests to less critical code whenever you have extra time<ul> <li>Increases code quality when time permits</li> </ul> </li> </ul>"},{"location":"Testing_2_TDD/#whatwhen-not-to-test","title":"What/When NOT to Test","text":"<p>Automated Testing</p> <ul> <li> Do not   write tests for trivial code</li> <li> Do not   write trivial tests that don\u2019t add benefit to your process</li> <li> Do not   use unit testing to test system level functions<ul> <li>Better covered by integration tests or manual testing, as opposed to unit testing</li> <li>Integration test recommendations coming soon</li> </ul> </li> <li> Do not   write tests while the application requirements are still rapidly changing<ul> <li>Remember, the requirements must be clearly defined up front in order to write meaningful tests and quality code</li> </ul> </li> <li> Do not   wait until the end of the application development to write all your tests<ul> <li>It is quite easy to end up with a lot of code that is difficult to test because it is not written in a modular way</li> </ul> </li> </ul> <p></p>"},{"location":"Testing_2_TDD/#backfilling-unit-tests-into-existing-projects","title":"Backfilling Unit Tests into Existing Projects","text":"<p>Although Test Driven Development is indeed the best way to work, there will be some instances where you will be forced to backfill unit tests rather than integrate them as you go.</p> <p>Most commonly, this will occur if you are working on an established / existing project that does not yet have any unit tests implemented.</p> <p>The unit tests that you should definitely and immediately implement (even if no other tests exist yet) are tests for new bugs that you encounter and fix.</p> <p>Without a doubt, it is valuable to backfill unit tests!</p> <p>However, there are some additional considerations / tips to keep in mind for this situation. Therefore, here are some tips for backfilling unit tests: </p> <p></p> <ul> <li>Understand the existing code. Define or find the spec for this code, because those are the \u201crules\u201d that you will be testing for.</li> <li>Review your existing manual test plan and identify the tests that you can automate</li> <li>Wait until the end of development for features that are already in progress<ul> <li>If you are refactoring existing code or the application is in flux, do not write the unit tests yet</li> <li>Since the tests were not the very first thing you did (aka TDD), they should be the very last thing you do</li> <li>Brand new features should be implemented with TDD</li> </ul> </li> <li>You may want/need to refactor existing code to make it more testable</li> <li>Do not test trivial things<ul> <li>This is especially a risk when you are backfilling</li> <li>Focus on things that are in the project specification. If you are writing tests for things that are not in the spec, this is a hint that they might be trivial / unhelpful / meaningless</li> <li>Test things that you actually expect might break in the future</li> </ul> </li> <li>Make sure you are adding value<ul> <li>Don\u2019t backfill just for the sake of backfilling. Make the tests count.</li> <li>Put in enough effort so that you trust the results of the test even though they were an afterthought.</li> <li>If no value is added, you will not convince others (or yourself) to write unit tests for projects in the future</li> </ul> </li> </ul>"},{"location":"Testing_3_BnRUnitTesting/","title":"B&amp;R Unit Testing","text":""},{"location":"Testing_3_BnRUnitTesting/#introductory-resources","title":"Introductory Resources","text":"<p>For a step-by-step guide on how to set up and use B&amp;R Unit Testing, refer to the guide from AutomationCON 2021. This has been included as a template file.</p> <p></p>"},{"location":"Testing_3_BnRUnitTesting/#dedicated-unit-test-configuration","title":"Dedicated Unit Test Configuration","text":"<p>The unit test tasks should not be deployed on a commissioned machine. Therefore, you should have a dedicated configuration in the AS project for unit testing.</p> <p></p>"},{"location":"Testing_3_BnRUnitTesting/#tips-for-writing-in-c","title":"Tips for Writing in C","text":"<p>B&amp;R Unit Tests must be written in the C programming language. The task under test can be written in any programming language (ST, ladder, etc), but the tests themselves have to be in C.</p> <p>Here are a few tips / tricks to help you transition quickly from ST to C:</p> Topic ST C Assignment operator := = Address reference ADR(var) &amp;var End of line ; ; Comment // // Equality = == Inequality &lt;&gt; != \u201cAnd\u201d operator AND &amp;&amp; \u201cOr\u201d operator OR \u201cNot\u201d operator NOT ! String boundary \u2018 \u201c Dynamic variable Link Link <p>For loop:</p> ST C FOR Var1 := 1 TO 9 DO\u2003//codeEND_FOR for (Var1 = 1; Var1&lt;10, Var1++)\u2003//code} <p>Case statement:</p> ST C CASE (stateVar) OF\u2002STATE1: \u2003//code\u2002STATE2:\u2003//codeEND_CASE Switch (stateVar){\u2002case 1:\u2003//code\u2003break;\u2002case2:\u2003//code\u2003break;}break; <p>If statement:</p> ST C IF (condition) THEN\u2003//codeELSIF(condition) THEN\u2003//codeELSE\u2003//codeEND_IF if(condition) {\u2003//code} else if(condition) {\u2003//code} else <p>Also note in C if (i = 0) is perfectly valid and assigns 0 to i and evaluates as false.  Some people recommend reversing the statement so that the compiler will catch mistypes (e.g. if (0 = i) would not compile if you really meant if (0 == i))</p> <p>And for loop exit condition is always &lt;= in ST but you can decide &lt; or &lt;= in C.</p>"},{"location":"Testing_3_BnRUnitTesting/#built-in-tests","title":"Built-In Tests","text":"<p>The following tests are built into the B&amp;R Unit Testing framework. Use cases are provided in the template files.</p> <ul> <li> <p>Setup &amp; Teardown</p> <ul> <li>These tests are used to clean things up before / after the tests run. More specifically:<ul> <li>_SETUP_TEST: Runs before each individual test</li> <li>_TEARDOWN_TEST: Runs after each individual test</li> <li>_SETUP_SET: Runs before the entire group of tests in the test suite</li> <li>_TEARDOWN_SET: Runs after the entire group of tests in the test suite</li> </ul> </li> </ul> </li> <li> <p>Cyclic code</p> <ul> <li>The _CYCLIC_SET test code is called once per program cycle, as long as the test set is active (in progress)</li> <li>Use cases:<ul> <li>Increment a timeout counter</li> <li>Call mapp FUBs that are under test</li> </ul> </li> </ul> </li> </ul>"},{"location":"Testing_3_BnRUnitTesting/#test-structure","title":"Test Structure","text":"<p>Each test should have 3 fundamental sections:</p> <ol> <li>Arrange<ul> <li>Sets up the test case</li> <li>Any required settings, parameters, or other preparation needed for that specific test case should be performed here</li> </ul> </li> <li>Act<ul> <li>Calls the function to be tested</li> <li>Act steps should cover the main thing to be tested</li> </ul> </li> <li>Assert<ul> <li>Assert expected outcome</li> </ul> </li> </ol> <p>For simple tests, this can be accomplished as shown below:</p> <pre><code>_TEST testCase1(void)\n\n{\n\n// Arrange\n\n    instMyCalc.CalcOperator = splMyCalcOPERATOR_ADD; \n    instMyCalc.Param1 = 1; \n    instMyCalc.Param2 = 2;\n\n// Act\n\n    MyCalculator(&amp;instMyCalc);\n\n// Assert\n\n    TEST_ASSERT_EQUAL_INT(3, instMyCalc.Result ); \n    TEST_ASSERT_EQUAL_INT(ERR_OK, instMyCalc.Status );\n\n}\n</code></pre> <p>For more advanced tests or tests for asynchronous function blocks, these sections should be implemented in a case statement.</p> <p>This allows the FUBs to be called until they complete the asynchronous action (since they are called within _CYCLIC_SET).</p> <p>For example: </p> <pre><code>_TEST PowerOn(void)\n{   \n    TIMEOUT_TEST_CASE    \n    switch (TestState)    \n  {        \n        case TEST_ARRANGE:          \n            TestState = TEST_ACT;        \n        break;        \n\n        case TEST_ACT:            \n            switch (ActSubState)            \n            {                \n                case 0:                    \n                    AxisControl.Command.Power = true;                    \n                    ActSubState = 1;                \n                break;                \n\n                case 1:                    \n                    TEST_BUSY_CONDITION(AxisControl.Status.Busy == true);                    \n                    TestState = TEST_ASSERT;                \n                break;            \n            }        \n        break;        \n\n        case TEST_ASSERT:            \n            TEST_ASSERT(AxisControl.Status.IsPowered);            \n            TEST_DONE;        \n        break;    \n    }\n\n    TEST_BUSY;\n}\n</code></pre>"},{"location":"Testing_3_BnRUnitTesting/#return-statements","title":"Return Statements","text":"<p>Each test must always provide a return statement in every scan of the test. The possible return statements are Busy, Abort, or Done (full list shown below). </p> <p></p> <p>It is common practice to put TEST_BUSY outside of your case statement so that the default return statement is that the test is busy.</p> <p>When one of these return statements is executed, the test immediately ends. No subsequent code will run. Therefore, in the screenshot below, we don\u2019t technically need the \u201cbreak;\u201d after TEST_DONE, but it is included for clarity nonetheless. This also means that you should have your FUB calls at the top of the test, rather than at the end. </p> <p></p>"},{"location":"Testing_3_BnRUnitTesting/#use-case-busy-and-abort-return-statements","title":"Use Case: Busy and Abort Return Statements","text":"<p>If you are testing asynchronous function blocks, utilize the Busy and Abort conditions to allow for the FUB to finish processing.</p> <p>Use TEST_BUSY_CONDITION(fub.Busy == false) or TEST_BUSY_CONDITION(fub.Status == 65535) to wait for the FUB to finish being busy.</p> <p>Use TEST_ABORT_CONDITION(fub.Status != 0) to abort the test in the event of an error.</p> <p>Examples:</p> <ul> <li>DirInfo(&amp;DirInfo_UT);</li> <li>TEST_BUSY_CONDITION(DirInfo_UT.status == 65535);</li> <li>TEST_ABORT_CONDITION(DirInfo_UT.status != 0);</li> </ul>"},{"location":"Testing_3_BnRUnitTesting/#test-asserts","title":"Test Asserts","text":"<p>An assert statement is used to declare the expected/passing result of the test.</p> <p>The most basic assert is TEST_ASSERT(condition), where the asserted condition is a Boolean value.</p> <p>A full list of available asserts is availabne here. </p>"},{"location":"Testing_3_BnRUnitTesting/#timeout-counter","title":"Timeout Counter","text":"<p>It recommended to implement a timeout counter to fail a test if it gets stuck for too long. The test will be failed if the counter exceeds a certain value. </p> <p>To implement the timeout counter:</p> <ol> <li>Copy the code for the TIMEOUT_TEST_CASE macro (within the template test file) to the top of your test suite file (right beneath the #include section). This macro will force the test to fail if the cycleCount is exceeded. The rest of the tests in the test suite will subsequently run as usual.</li> <li>Adjust the cycleCount to a value that makes sense for your testing</li> <li>Declare the following variables test task variable file:<ul> <li>\u201cActSubState\u201d of type USINT</li> <li>\u201ccycleCount\u201d of type USINT</li> </ul> </li> <li>Within _CYCLIC_SET, increment cycleCount (cycleCount++)</li> <li>Call TIMEOUT_TEST_CASE at the top of each test</li> <li>Now, each test will be protected from getting stuck / never ending</li> </ol> <p></p>"},{"location":"Testing_3_BnRUnitTesting/#strategy-for-uiconnect-commands-in-tests","title":"Strategy for UIConnect Commands in Tests","text":"<p>If you need to use commands from a UIConnect structure in a test, you must follow this order of operations within a case statement:</p> <ul> <li>Trigger the command</li> <li>Wait for the status that the command is in progress (whatever that may be)</li> <li>Wait for it to return to idle</li> <li>Then SOMETIMES wait for it to refresh (it\u2019ll automatically do this depending on what command you run)</li> <li>Wait for it to return to idle AGAIN</li> <li>Then  you can move on in your testing process</li> </ul> <p>Not following this order of operations causes intermittent failures.</p> <p>Example: Note that the UIConnect case statement is embedded within the TEST_ACT case of the overall case statement.</p> <p></p>"},{"location":"Testing_3_BnRUnitTesting/#variable-mapping-file","title":"Variable Mapping File","text":"<p>In most (if not all) tests, you will need to use a value of a local variable within the task under test within the unit test. To get that variable data into the unit test task, use a Variable Mapping File (.vvm). </p> <p>Steps:</p> <ol> <li>Add the local variable and type file of the task under test as a reference to the unit test task<ul> <li>This way, the unit test task has its own instance of every variable within the task under test</li> </ul> </li> <li>Add a Variable Mapping File (.vvm) to the unit test configuration</li> <li>Within the .vvm, map the local variables from the task under test to the equivalent local variable instances within the unit test task.<ul> <li>Variable mapping goes in both directions: inputs from the task under test to the unit test task, and outputs from the unit test task to the task under test</li> </ul> </li> </ol> <p></p> <ul> <li>Note that you cannot directly map function block outputs from the task under test to the unit test task function block outputs</li> <li>As a result, you need to make a \"middle man\" structure to capture the value of the FUB outputs and bring them in to the unit test task</li> <li>In the screenshot above, this corresponds to the MpBlockStatus structure in the unit test task</li> </ul>"},{"location":"Testing_3_BnRUnitTesting/#debugging","title":"Debugging","text":"<p>Breakpoints can be set directly in the unit test code. Therefore, when a unit test fails, use the debugger to troubleshoot the problem.</p> <p></p>"},{"location":"Testing_3_BnRUnitTesting/#code-coverage","title":"Code Coverage","text":"<p>With code coverage enabled you can see how much of you code is covered by your testing.  This can help assess the quality of your test cases. Code coverage in Automation Studio only works for C/C++ tasks/libraries and GCC 6.3.0</p> <p>EmbGCov-Demo project</p> <p>Usage:</p> <ol> <li>Install gcov.  See here for installation instructions</li> <li>Add the Unittest solution with version 2.0.1.65</li> <li>Add the EmbGcov and EmbGcovW library ( Make sure to deploy both libraries in the PLC )</li> <li>Change the GCC version to '6.3.0' and add the '\\Logical\\Libraries\\EmbGcov' to the additional include directories </li> <li>Add the '--codecoverage' to the Additional build options in the task and or library     </li> <li>Extend the TEARDOWN_SET<ul> <li>Include the EmbGcov.h</li> <li>Add the function 'EmbGcovExit();' so that after the test is complete the data is saved to the harddrive.</li> <li>In case of a pure C task add a dummy C++ file with the bur_heap_size declaration. This will add some implementations we need.</li> <li>In case you want to use code coverage on a library add a dummy function with the 'EmbGcovExit();' as well. ( If it's a dynamic library please add the function in a CPP file )</li> </ul> </li> <li>Run the python script to generate the report<ul> <li> <pre><code>    C:\\&gt;python ProcessCodeCoverage.py --project &lt;project path&gt; --config TS_UnitTest_Sample\n</code></pre> </li> </ul> </li> </ol>"},{"location":"Testing_4_IntegrationTesting/","title":"Integration Testing","text":"<p>pytest and Selenium are the tools we typically use at B&amp;R for mapp View integration testing.</p> <ul> <li>pytest: Python testing suite</li> <li>Selenium: driver interface for web browsers. Allows you to interact with the Chrome browser.</li> </ul>"},{"location":"Testing_4_IntegrationTesting/#integration-testing-workflow","title":"Integration Testing Workflow","text":"<p>The overall workflow is as follows: </p> <ul> <li>Place all of your test files (test_*.py or *_test.py) within one directory of your project repository</li> <li>Call pytest in your Jenkinsfile using the helper function RunMappViewIntegrationTests()<ul> <li>This helper function allows you to point to another directory that holds your tests, rather than requiring it to be the same directory as your Jenkinsfile</li> </ul> </li> </ul> <p>For more details on the Jenkinsfile, refer to the Build Server section of the DevOps Package.</p>"},{"location":"Testing_4_IntegrationTesting/#pytest","title":"pytest","text":"<p>The pytest framework makes it easy to write small, readable tests, and can scale to support complex functional testing for applications and libraries.</p> <p>Install pytest with:</p> <pre><code>pip install pytest\n</code></pre> <p>Run pytest with:</p> <pre><code>pytest\n</code></pre> <p>pytest finds all files within your current directory that are named test_*.py or *_test.py (where * can be anything) and runs those tests.</p>"},{"location":"Testing_4_IntegrationTesting/#assert","title":"Assert","text":"<p>Unlike B&amp;R unit tests, there is only 1 assert statement in pytest:</p> <pre><code>assert \\&lt;Boolean expression&gt;, \u201coptional failure message\u201d\n</code></pre> <p>Example: <pre><code>def f():\n    return 3\ndef test_function():\n    assert f() == 4, \u201cValue was not 4\u201d\n\ndef test_function_2():\n    my_list = [\u201capple\u201d, \u201cbanana\u201d]\n    assert \u201capple\u201d in my_list\n</code></pre></p>"},{"location":"Testing_4_IntegrationTesting/#fixtures","title":"Fixtures","text":"<p>A fixture provides a defined, reliable, and consistent context for the tests. This could include an environment (e.g., a database configured with known parameters) or content (such as a dataset).</p> <p>Fixtures are essentially subroutines that each test case requests, by adding it as a parameter to the test case. </p> <p>Fixtures define the steps and data that constitute the  setup, teardown, and arrange phase of a test. In pytest, they are functions you define that serve this purpose.</p> <p>Fixtures are defined with the @pytest.fixture decorator on a function</p> <p>Example:</p> <pre><code>import pytest\n\nclass Fruit:\n    def __init__(self, name):\n        self.name = name\n    def __eq__(self, other):\n        return self.name == other.name\n\n@pytest.fixture\ndef my_fruit():\n    return Fruit(\"apple\")\n\n@pytest.fixture\ndef fruit_basket(my_fruit):\n    return [Fruit(\"banana\"), my_fruit]\n\ndef test_my_fruit_in_basket(my_fruit, fruit_basket):\n    assert my_fruit in fruit_basket\n</code></pre> <p>Fixtures can have scopes, such as: function, module, class, package, session.</p> <p>\u201cYield\u201d inside a fixture stops the function at that point but will resume at that point after the test  function runs (Useful for creating a setup and teardown within a single fixture).</p> <p>Example:</p> <pre><code>@pytest.fixture(scope=\"class\")\ndef opcua_setup():\n        #Setup\n        opcua_client = Client(\"opc.tcp://localhost:4840/\")\n        opcua_client.connect()\n        yield opcua_client\n        #Teardown\n        opcua_client.disconnect()\n</code></pre>"},{"location":"Testing_4_IntegrationTesting/#parameterized-test","title":"Parameterized Test","text":"<p>pytest enables you to run the same test multiple times with different inputs (i.e., test parameterization). </p> <p>Do this by using the @pytest.mark.parameterize function decorator. </p> <p>Example: </p> <pre><code>@pytest.mark.parametrize(\"test_input,expected\", [(\"3+5\", 8), (\"2+4\", 6), (\"6*9\", 42)])\n\ndef test_eval(test_input, expected):\n\nassert eval(test_input) == expected\n</code></pre>"},{"location":"Testing_4_IntegrationTesting/#selenium","title":"Selenium","text":"<p>Selenium allows you to automate web browsers, primarily for testing purposes. </p> <p>Install selenium with:</p> <pre><code>pip install selenium\n</code></pre> <p>Basic components:</p> <ul> <li>Session<ul> <li>driver = webdriver.Chrome()</li> </ul> </li> <li>Take action on browser<ul> <li>driver.get(\u201chttp://localhost:81/index.html?visuId=mappFramework\u201d)</li> </ul> </li> <li>Request browser information<ul> <li>title = driver.title</li> </ul> </li> <li>Find an element(s)<ul> <li>text_box = driver.find_element(by=By.NAME, value=\"my-text\")</li> <li>submit_button = driver.find_element(by=By.CSS_SELECTOR, value=\"button\")</li> </ul> </li> <li>Take action on an element<ul> <li>text_box.send_keys(\"Selenium\")</li> <li>submit_button.click()</li> </ul> </li> <li>Request element information<ul> <li>value = message.text</li> </ul> </li> <li>End the session (close the browser)<ul> <li>driver.quit()</li> </ul> </li> </ul> <p>Find elements using Developer tools in Chrome by pressing F12, or via the \u201c\u2026\u201d menu:</p> <p></p> <p></p>"},{"location":"Testing_4_IntegrationTesting/#helper-functions-integrationtestbasepy","title":"Helper functions: IntegrationTestBase.py","text":"<ul> <li>get_element \u2013 returns an element</li> <li>wait_for_element \u2013 waits for an element to be available</li> <li>wait_and_click_element \u2013 waits for an element to be available and click the element</li> <li>wait_for_init_page \u2013 waits for the initial page to load</li> <li>load_content \u2013 clicks a button that loads a content and waits for the content to be loaded</li> <li>set_input \u2013 sets an input to a value</li> <li>get_value \u2013 gets the value of an output</li> <li>get_table_column \u2013 returns a column from a table</li> <li>get_table_row \u2013 returns the row of a table, row is identified by a value in a specified column</li> <li>select_table_row \u2013 clicks a row of a table, row is identified by a value in a specified column</li> <li>select_downdown_item \u2013 select an item in a dropdown input</li> <li>get_open_dialog_id \u2013 returns the id of the currently opened dialog</li> <li>read_variable \u2013 reads a variable via OpcUa</li> <li>write_variable \u2013 writes a variable via OpcUa</li> </ul> <p>Included fixtures within the DevOps package:</p> <ul> <li>visu_setup()<ul> <li>Selenium Chrome Webdriver</li> <li>Will be used in every test</li> </ul> </li> <li>opcua_setup()<ul> <li>OpcUa client</li> <li>Also need to install asyncua and opcua packages (pip install asyncua opcua)</li> <li>Will be needed in most tests</li> </ul> </li> <li>login()<ul> <li>logs in as a specific user</li> </ul> </li> </ul> <p>Example:</p> <p></p>"},{"location":"Testing_5_ManualTesting/","title":"Manual Testing","text":""},{"location":"Testing_5_ManualTesting/#template-excel-file","title":"Template Excel File","text":"<p>For the situations where it is not possible to write an automated test, manual testing must be done. To help keep track of the status of the manual tests, there is a template Excel file provided in this package.</p> <p>Details for how to use the file are included on the Overview tab of the sheet. </p> <p></p> <p></p>"},{"location":"Testing_5_ManualTesting/#multiple-asserts","title":"Multiple Asserts","text":"<p>When defining your manual tests, it can be advantageous to combine more than one expected result (assert) into one test. Manual testing is more \u201cexpensive\u201d since it takes more time. So, designing your tests in such a way that a couple of things that are naturally related can be checked over the course of a test can make sense (as opposed to one dedicated assert per test).</p> <p>However, this must be balanced with being able to get useful information out of a failed test. If your test is written in such a way that 10 things are checked all within one test, then if that test fails you will spend additional time trying to figure out exactly where/how it failed.</p> <p>Keep this in mind as you design your tests. </p>"},{"location":"Testing_5_ManualTesting/#good-examples","title":"Good Examples","text":"<p>Multiple asserts that are related to minimize testing effort:</p> <p> </p>"},{"location":"Testing_5_ManualTesting/#bad-examples","title":"Bad Examples","text":"<p>Tedious test that should be automated (error prone when executed manually):</p> <p></p>"},{"location":"VersionControl/","title":"Version Control","text":""},{"location":"VersionControl/#before-we-get-started","title":"Before we get started","text":"<p>There is a huge amount of great material online that covers the \"what\", \"why\", and \"how\" of version control.</p> <p>In these materials, we will link to those external resources for general topics.</p> <p>We will primarily focus here on the things that are specific to B&amp;R. </p> <p></p>"},{"location":"VersionControl/#version-control-basics","title":"Version Control Basics","text":"<p>Definition</p> <p>Benefits</p>"},{"location":"VersionControl/#build-version-framework","title":"Build Version Framework","text":"<p>The Build Version framework is a tool that automatically pulls git repository and PC information, and adds it to an AS project to display directly on the mapp View HMI.</p> <p>This allows you to always be certain exactly which version of the software is running on the machine!</p> <p>The build version framework installer is available on GitHub here. Note that to import this framework into your AS project, you must have the mapp Framework installed as well in order to use the import tool. You aren\u2019t required to use the mapp Framework itself, but you do need to use the corresonding import tool. </p> <p></p>"},{"location":"VersionControl_01_BuildVersionFramework/","title":"Build Version Framework","text":"<p>The Build Version framework is a tool that automatically pulls git repository / PC information, and conveniently adds it to an AS project. This makes it very quick and easy to display this information directly on the mapp View HMI.</p> <p>This allows you to always be certain exactly which version of the software is running on the machine!</p> <p>The build version framework installer is available on GitHub here. Note that to import this framework into your AS project, you must have the mapp Framework installed as well in order to use the import tool. You aren\u2019t required to use the mapp Framework itself, but you do need to use the corresonding import tool. </p> <p></p>"},{"location":"VersionControl_0_SummaryOfTemplateFiles/","title":"Template Files","text":"<p>The following two template files are provided within the DevOps package:</p> <ul> <li>A standardized .gitignore file</li> <li>A Git configuration script</li> <li>authors-export.ps1 script</li> </ul>"},{"location":"VersionControl_10_ASProjectSettings/","title":"AS Project Settings","text":"<p>On the Build tab of the CPU properties, it is recommended to add the .git file extension to the list for \"Objects ignored for build warnings 9232 and 9233\".</p> <p>This will prevent those warnings from triggering because .git files exist in the project directory which are not directly related to the project itself. </p> <p></p>"},{"location":"VersionControl_11_MigratingFromSVN/","title":"Migrating from SVN","text":""},{"location":"VersionControl_11_MigratingFromSVN/#create-authors-file","title":"Create Authors File","text":"<p>The authors files will translate svn usernames to email addresses for git.</p> <ul> <li>PowerShell command to extract all authors from SVN:<ul> <li>Must have svn command line tools installed</li> <li>This is an option when installing TortoiseSVN</li> <li>If you are unsure whether you installed it or you know that you didn\u2019t, you can just run the TortoiseSVN installer again and take care to include this option</li> <li>Run the  authors-export.ps1 script from within your svn directory</li> </ul> </li> <li>Edit authors.txt file to match the following format: <pre><code>buchananw = Wesley Buchanan &lt;wesley.buchanan@br-automation.com&gt;\nwww-data = system &lt;noreply@br-automation.com&gt;\n</code></pre></li> </ul>"},{"location":"VersionControl_11_MigratingFromSVN/#clone-repository","title":"Clone Repository","text":"<p>For standard layout of trunk, branchs, tags:</p> <pre><code>git svn clone \\[SVN repo URL\\] --prefix=svn/ --no-metadata --authors-file \"authors.txt\" --stdlayout\n</code></pre> <p>For non-standard layout (B&amp;R\u2019s svn repository):</p> <pre><code>git svn init \\[SVN repo URL\\] --no-metadata\ngit svn fetch \u2013authors-file \"authors.txt\"\n</code></pre>"},{"location":"VersionControl_11_MigratingFromSVN/#convert-svn-ignore","title":"Convert SVN ignore","text":"<pre><code>git svn show-ignore &gt; .gitignore\ngit add .gitignore\ngit commit --m \u2018convert svn:ignore to .gitignore\u2019\n</code></pre>"},{"location":"VersionControl_11_MigratingFromSVN/#push-to-new-git-repository","title":"Push to New Git Repository","text":"<pre><code>git remote add origin \\[my new git repo\\].git\ngit add .\ngit commit --m \u2018migrating svn to git\u2019\ngit push --u origin main\n</code></pre>"},{"location":"VersionControl_11_MigratingFromSVN/#sync-new-svn-commits","title":"Sync New SVN Commits","text":"<pre><code>git svn rebase\ngit push\n</code></pre>"},{"location":"VersionControl_1_Git/","title":"Git","text":""},{"location":"VersionControl_1_Git/#git-basics","title":"Git Basics","text":"<p>What is Git?</p> <p>Why use Git?</p> <p>YouTube Tutorial Series</p>"},{"location":"VersionControl_1_Git/#installation","title":"Installation","text":"<p>Download here. Installation Considerations:</p> <ul> <li>Use default installations settings, except for selecting your preferred default text editor (e.g., Notepad++)</li> <li>After installation, run the provided script  GitConfigHelper.bat  to accomplish the following:</li> <li>Change the default branch name to 'main' (as opposed to 'master')</li> <li>Allow a secure connection</li> <li>Set the credential manager to the Windows credential manager core</li> </ul>"},{"location":"VersionControl_1_Git/#hosting-services","title":"Hosting Services","text":"<p>A hosting service enables you to manage a Git repository. </p> <p>There are many choices for hosting services\\, but the two that we use at B&amp;R are Bitbucket and GitHub. </p> <p>Alternatives include Microsoft Azure Repos, GitLab, Amazon AWS CodeCommit, and so on.</p> <p></p>"},{"location":"VersionControl_1_Git/#create-a-repo","title":"Create a Repo","text":"<p>Create a repository in Bitbucket</p> <p>Create a repository in GitHub </p>"},{"location":"VersionControl_1_Git/#git-client","title":"Git Client","text":"<p>A Git client allows you to interact with the Git repository via a visual interface, without the command line.</p> <p>Just as with the hosting service, there are many options for Git clients. At B&amp;R, we use Sourcetree. </p> <p>Alternate options include Tortoise Git, Git Extensions, GitHub Desktop, and so on.</p> <p></p>"},{"location":"VersionControl_2_Sourcetree/","title":"Sourcetree","text":""},{"location":"VersionControl_2_Sourcetree/#installation","title":"Installation","text":"<p>Download</p> <p>Installation Guide</p>"},{"location":"VersionControl_2_Sourcetree/#add-a-remote-account","title":"Add a Remote Account","text":"<p>After installation\\, click on the Remote tab and \"Add an account\u2026\".</p> <p></p> <p>In the resulting pop-up, change the hosting service dropdown to \"GitHub\" or \"Bitbucket Server\" accordingly, and then click the button to either \"Refresh OAuth Token\" or \"Refresh Password\"</p> <p></p> <p>Follow the prompts to login on GitHub/Bitbucket and approve the authorization.</p>"},{"location":"VersionControl_2_Sourcetree/#identify-external-merge-tool","title":"Identify External Merge Tool","text":"<p>The tool we use at B&amp;R to resolving merge conflicts is Visual Studio Code. You can download it here.</p> <p>This tool must be identified in the Sourcetree options. Therefore, after installing Sourcetree and Visual Studio Code, go to Tools \u2192 Options. Select the \u201cDiff\u201d tab.</p> <p>Within the \u201cExternal Diff / Merge\u201d section:</p> <ul> <li>Set the External Diff Tool dropdown to \u201cCustom\u201d</li> <li>Set the Diff Command to:C:\\Users\\%USERNAME%\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe</li> <li>Set the Diff Command Arguments to: --diff --wait \"$LOCAL\" \"$REMOTE\"</li> <li>Set the Merge Tool dropdown to \u201cCustom\u201d</li> <li>Set the Merge Tool to: C:\\Users\\%USERNAME%\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe</li> <li>Set the Merge Tool Arguments to: -n --wait \"$MERGED\"</li> </ul> <p></p>"},{"location":"VersionControl_2_Sourcetree/#authentication-issue-mistyped-password","title":"Authentication Issue - Mistyped Password","text":"<p>If you mistype your password while authorizing your Bitbucket/GitHub account, follow the instructions in this post to fully delete the incorrect password and try again.</p> <p></p>"},{"location":"VersionControl_2_Sourcetree/#clone-repo","title":"Clone Repo","text":"<p>Once your account is activated and working, you can clone a repository from any organization that your account has access to. Select the organization from the dropdown on the right.</p> <p>If you don\u2019t see any organizations in your dropdown, contact your project leader so that they can grant you access.</p> <p>The list will then refresh with all available repositories. Click \"Clone\" next to the one you want to clone.</p> <p></p>"},{"location":"VersionControl_2_Sourcetree/#checkout-branch","title":"Checkout Branch","text":"<p>After you clone a repo, take care to check out the branch that you intend to work on.</p> <p>The branches that are available on the remote repository are located on the left beneath \"REMOTES\".</p> <p>Your local repository branches are listed under \"BRANCHES\".</p> <p>The branch that is bolded is the one that you are currently checked out to.</p> <p></p> <p>To check out a branch, either double click it or use the right click menu. If you\u2019re checking out a branch for the first time from the remote, make sure to keep the box checked so that the \"Local branch should track remote branch\".</p> <p></p>"},{"location":"VersionControl_2_Sourcetree/#standardized-gitignore-file","title":"Standardized .gitignore File","text":"<p>There are a handful of standardized .gitignore files floating around the B&amp;R universe. For example:</p> <ul> <li>Example 1</li> <li>Example 2</li> <li>Example 3</li> </ul> <p>If you are unsure where to start, the recommended standardized .gitignore file is included within the template files of this DevOps package (which closely matches Example 1 listed above). Note that this .gitignore file should be placed in the root directory of the project (the same directory as the .apj file).</p> <p>Make sure to add  and push  the .gitignore file to the repo BEFORE you add any files that should be ignored. If the .gitignore is not ignoring your files as expected, see here.</p>"},{"location":"VersionControl_2_Sourcetree/#tips-for-using-git-with-safety","title":"Tips for Using Git with Safety","text":"<p>If your project includes safety, then there are some additional considerations regarding the .gitignore file:</p> <ul> <li>You do NOT have to exclude the DLFiles folder when using Git (despite the fact that this is shown at GUID b8c69e5e-7579-4e41-b853-13cf9ccbef53). This is only required if you are using Subversion (not Git).</li> <li>You MUST INCLUDE all .set files within the safety project</li> <li>Our template .gitignore file contains this exception for you already</li> <li>Merging changes in a SafeDESIGNER project is not possible. Only one person can work on the SafeDESIGNER project at a time.</li> <li>Even if you don\u2019t make any changes but you simply open the SafeDESIGNER project or compile, several files within the project structure will indeed be updated. This is expected \u2013 please always commit and push these changes to keep everything in line and up to date.</li> <li>If it is frustrating for your workflow that many safety files will change each time you compile, then another option to consider is to completely exclude the SafeDESIGNER project from source control and instead include the SD project as a .zip file. Note that you will have to manually include this .zip file within the .gitignore file, since the template is configured to ignore all contained .zip files by default.</li> <li>Do not work in parallel!</li> </ul>"},{"location":"VersionControl_2_Sourcetree/#tips-for-using-git-with-vc4","title":"Tips for Using Git with VC4","text":"<p>If your project includes a VC4 visualization, do not work in parallel and try to merge changes via source control. Only one person should open or make changes to a VC4 visualization at a time.</p> <p>The reason is because Git compares XML line by line, but VC4 moves XML around liberally. Therefore, it is very easy to create many merge conflicts that are tedious to solve. It is better to avoid this situation entirely.</p>"},{"location":"VersionControl_3_Commits/","title":"Commits","text":""},{"location":"VersionControl_3_Commits/#commit-description","title":"Commit Description","text":"<p>When committing to the repo, include the Jira ID (if applicable) at the beginning of the commit description, along with a short sentence about what you changed. </p> <p>See here for recommendations on writing commit messages.</p> <p>Remember to commit often!</p> <p></p>"},{"location":"VersionControl_3_Commits/#how-to-undo-a-commit","title":"How to Undo a Commit","text":"<p>The following resources explain the strategies for handling several different undo situations in Git:</p> <ul> <li>Resource 1</li> <li>Resoruce 2</li> </ul> <p>These methods are executed directly in the terminal. To access the terminal, click the \"Terminal\" icon within your repo in Sourcetree at the top right.</p> <p></p>"},{"location":"VersionControl_3_Commits/#reverse-commit","title":"Reverse Commit","text":"<p>Instead of undoing a commit, you can also create a new commit which reverses all of the changes in the selected commit.</p> <p>This can be executed directly from the Sourcetree History view via the right-click menu.</p> <p></p>"},{"location":"VersionControl_3_Commits/#push-to-pull-from-the-remote","title":"Push to / Pull from the Remote","text":"<p>Any commits you make will be stored in your local repository.</p> <p>In order to make the changes available to everyone else working on the project, you must  push  to the remote repository.</p> <p>Similarly, in order to obtain the changes that other teammates have made, you must  pull  from the remote repository.</p> <p></p>"},{"location":"VersionControl_4_Branching/","title":"Branching","text":""},{"location":"VersionControl_4_Branching/#the-basics","title":"The Basics","text":"<p>Branch Management</p> <p>Gitflow Workflow</p> <p>Creating and Merging Branches (YouTube video)</p>"},{"location":"VersionControl_4_Branching/#gitflow-branching","title":"Gitflow Branching","text":"<p>At B&amp;R we follow the Gitflow branch strategy:</p> <ul> <li>Two long-living branches:<ul> <li>main<ul> <li>Officially released code</li> <li>As bug-free as possible</li> <li>Each merge into main must be tagged with a version number</li> <li>There is only 1 instance of the main branch, and it is never deleted</li> </ul> </li> <li>develop<ul> <li>Integration branch for new features</li> <li>Latest development version ready for testing (may contain bugs)</li> <li>Should compile and run on real hardware</li> <li>There is only 1 instance of the develop branch, and it is never deleted</li> <li>Create a  release  branch from the develop branch once you are ready to prep for release</li> </ul> </li> </ul> </li> <li>Supporting branches (temporary):<ul> <li>feature<ul> <li>Used for developing new features</li> <li>Several feature branches can exist simultaneously</li> <li>Can be both local and remote</li> <li>Useful anytime you expect to commit multiple times for one particular feature, even if the feature is completed within a short period of time</li> <li>Merged back into  develop  after the feature has been reviewed and it is ready for integration testing. Then the branch is deleted.</li> </ul> </li> <li>release<ul> <li>branched from  develop  once all planned bugs/features are merged for the next release</li> <li>Only used for bug fixes, documentation, and other release oriented tasks (no new features)</li> <li>Merged back into  main and develop once testing is complete and discovered bugs are fixed. Then the branch is deleted.</li> </ul> </li> <li>hotfix<ul> <li>Branched from  main  when critical bug found in production that must be solved immediately</li> <li>Used to develop critical bugfixes</li> <li>Merged back into  main and develop. Then the branch is deleted.</li> </ul> </li> </ul> </li> </ul> <p></p>"},{"location":"VersionControl_4_Branching/#manual-vs-git-flow","title":"Manual vs Git-flow","text":"<p>You can use the icons at the top of Sourcetree to manually branch and merge according to the strategy previously described.</p> <p></p> <p>Alternatively, you can use the Git-flow icon in the top right. Git-flow guides you to follow the branching strategy with a simple GUI. This is the recommended method.</p> <p></p>"},{"location":"VersionControl_4_Branching/#git-flow","title":"Git-flow","text":"<p>When you first launch Git-flow, you must initialize the repo for Git-flow. Remember to change the production branch name to \"main\" (\"master\" is the default value).</p> <p></p> <p>After initialization, click the \"Git-flow\" icon again to start a new action.</p> <p>As application engineers, you will typically select the \"Start New Feature\" action. The project lead will start the release or hotfixes.</p> <p></p>"},{"location":"VersionControl_4_Branching/#git-flow-feature","title":"Git-flow Feature","text":"<p>When you start a new feature, give it a name and then confirm that it starts at the \"develop\" branch.</p> <p></p> <p>Commit and push to your feature branch as needed during development.</p> <p>Execute a code review (more on this later).</p> <p>Once complete and reviewed, click the \"Git-flow\" icon again and select \"Finish Feature\". This will merge the feature branch back into develop for you and delete the feature branch.</p> <p></p>"},{"location":"VersionControl_5_ResolvingMergeConflicts/","title":"Resolving Merge Conflicts","text":""},{"location":"VersionControl_5_ResolvingMergeConflicts/#definition","title":"Definition","text":"<ul> <li>A merge conflict means there are incompatible changes in the files you are trying to merge together</li> <li>This can happen, for example, when you are trying to merge two branches together</li> <li>This can also happen if you and a teammate are editing the same lines in the same file. For example:<ul> <li>Your teammate commits and pushes changes to the server</li> <li>You make changes to the same lines of code and commit the same file to your local server</li> <li>Prior to pushing your changes, you must pull. However, upon trying to pull, you will be notified of the conflict between your local file and the change recently pushed by your teammate</li> </ul> </li> <li>This section will guide you through how to resolve such merge conflicts</li> <li>As mentioned previously, we at B&amp;R use Visual Studio Code to resolve merge conflicts</li> </ul>"},{"location":"VersionControl_5_ResolvingMergeConflicts/#how-to-resolve-merge-conflicts","title":"How to Resolve Merge Conflicts","text":"<p>Within Sourctree, conflicted files appear with an exclamation mark next to them after you\u2019ve committed and tried to pull changes from the server.</p> <p></p> <p>To resolve, right click on the conflicted file and select \"Resolve Conflicts \u2192 Launch External Merge Tool\".</p> <p></p> <p>Visual Studio Code will open. There are 3 options in Visual Studio Code to resolve a conflict:</p> <ul> <li>Accept Current Change</li> <li>Accept Incoming Change</li> <li>Accept Both Changes</li> </ul> <p>The Compare Changes option allows you to view the differences side-by-side.</p> <p>These actions are integrated directly within Visual Studio Code as button selections above each conflict:</p> <p></p> <p>The following example will be used to show the result of each of the 3 merge conflict options. In this example:</p> <ul> <li>\"x := x / 3;\" is the change to the line made locally. </li> <li>\"x := x * 3;\" is the change to the line that a teammate has already pushed to the server, which you have not successfully pulled yet. </li> </ul> <p></p>"},{"location":"VersionControl_5_ResolvingMergeConflicts/#accept-current-change","title":"Accept Current Change","text":"<p>Apply your local changes and disregard the changes from the server.</p> <p>Therefore, in this example, we keep the line  \"x := x / 3;\"</p> <p></p>"},{"location":"VersionControl_5_ResolvingMergeConflicts/#accept-incoming-change","title":"Accept Incoming Change","text":"<p>Apply the server\u2019s changes and disregard your local changes.</p> <p>Therefore, in this example, we use the line  \"x := x * 3;\"</p> <p></p>"},{"location":"VersionControl_5_ResolvingMergeConflicts/#accept-both-changes","title":"Accept Both Changes","text":"<p>Apply your local changes and  the server\u2019s changes.</p> <p>Therefore, in this example, we now have both lines  \"x := x / 3;\"  and  \"x := x * 3;\"</p> <p></p>"},{"location":"VersionControl_5_ResolvingMergeConflicts/#compare-changes","title":"Compare Changes","text":"<p>The Compare Changes option shows a side-by-side view of the conflicting differences.</p> <p></p>"},{"location":"VersionControl_6_CodeReview/","title":"Code Review Strategy","text":""},{"location":"VersionControl_6_CodeReview/#when-to-review","title":"When to Review","text":"<p>Prior  to closing out a feature via Git-flow (and therefore merging the feature into the develop branch), we recommend that the feature gets  reviewed  by a peer engineer or the project lead</p> <p>If any changes are required per the review, they would then be implemented on the same feature branch before it is closed</p>"},{"location":"VersionControl_6_CodeReview/#why-to-review","title":"Why to Review","text":"<p>There are 2 purposes of a code review:</p> <ol> <li>Increase the code quality<ul> <li>Confirm that the feature indeed works</li> <li>Brainstorm if the implementation is optimal or if it should be adjusted</li> </ul> </li> <li>Increase the number of people that are familiar with the code<ul> <li>By executing a review, this guarantees that at least one other person is familiar with the feature and how it is implemented in case the original developer becomes unavailable</li> </ul> </li> </ol>"},{"location":"VersionControl_6_CodeReview/#scheduling-code-reviews","title":"Scheduling Code Reviews","text":"<ul> <li>The best way to trigger a code review is via a pull request<ul> <li>This can be triggered from Sourcetree: right click on the branch and select \"pull request\"</li> </ul> </li> <li>Then the status of the pull requests will be visible to everyone who has access to the repository, and there will be a paper trail for all code reviews</li> <li>You can also choose to lock the develop/main branches so that a pull request is absolutely required before anything can be merged to it</li> </ul>"},{"location":"VersionControl_7_Versioning/","title":"Versioning","text":""},{"location":"VersionControl_7_Versioning/#tagging","title":"Tagging","text":"<p>Each merge into the main branch should be tagged with a version number.</p> <p>When you close a release via Git-flow, you can add the version number tag directly in the dialog box:</p> <p></p> <p>Git-flow will merge the release branch into main and develop. Afterwards, make sure to checkout and push both branches.</p>"},{"location":"VersionControl_7_Versioning/#version-number-scheme","title":"Version Number Scheme","text":"<p>The version number scheme we use at B&amp;R is:   XX . YY . ZZ </p> <ul> <li> XX = Major Revision <ul> <li>Incompatible with previous major revisions</li> </ul> </li> <li> __YY = Minor Revision __ <ul> <li>New features added</li> </ul> </li> <li> ZZ = Bug Fixes <ul> <li>No new features, just small changes / bugfixes</li> </ul> </li> </ul>"},{"location":"VersionControl_8_Submodules/","title":"Submodules","text":""},{"location":"VersionControl_8_Submodules/#definition-use-cases","title":"Definition &amp; Use Cases","text":"<ul> <li>A submodule is a reference to another git repository within your repository<ul> <li>The submodule repo (child repo) is managed completely independently</li> <li>The parent repo references a specific commit within the submodule that it is currently using</li> </ul> </li> <li>Uses Cases within an AS project:<ul> <li>Separating out project components (custom libraries, application modules)</li> <li>Same use case as a feature branch, but isolated to its own repository</li> <li>Delegating a part of the project to a third party</li> </ul> </li> </ul>"},{"location":"VersionControl_8_Submodules/#use-case-highlight-separating-out-project-components","title":"Use Case Highlight: Separating Out Project Components","text":""},{"location":"VersionControl_8_Submodules/#situation","title":"Situation","text":"<ul> <li>A project/repo is used for a series machine. There is a specific feature that is only needed for 1 machine. What is the best way to manage this?</li> </ul>"},{"location":"VersionControl_8_Submodules/#submodule-implementation","title":"Submodule Implementation","text":"<ul> <li>Use a submodule for the one-off feature.</li> <li>The submodule points to a package in the Logical View containing all of the files needed for the one-off feature.</li> <li>If Configuration View files are needed as well for the feature, they would still be placed in this folder so that one single submodule can manage the files. Then after you add the submodule to your project, you would have to manually add referenced files in the Configuration View to the appropriate files from that package.</li> <li>If you don\u2019t do it this way then you\u2019d have to manage 2 or more submodules for one feature, since a submodule can only point to one specific directory, which would be quite difficult to manage.</li> </ul>"},{"location":"VersionControl_8_Submodules/#example","title":"Example","text":"<ul> <li>One example where this submodule method works quite nicely is if the one-off feature could be contained completely in a library.</li> <li>There would be one version of the library that is used for the series of the machines, and another version of the library that is adjusted as needed for the one-off.</li> <li>In this case, the submodule would contain just that library. The project repo points to a submodule for that library:</li> <li>The main branch (for the series machines) points to a submodule with the commonly used library implementation</li> <li>Then there would be a separate branch for the one-off machine, which would point to a different submodule containing the modified version of the library</li> <li>In this situation, the code itself remains unchanged since we are just swapping out which library is being utilized. The inputs/outputs are consistent.</li> </ul>"},{"location":"VersionControl_8_Submodules/#caveat","title":"Caveat","text":"<ul> <li>If, however, the one-off feature is too tangled/embedded in the application to where it\u2019s not perfectly modular (e.g. you have to modify existing files, not just add new files), then this submodule method may not make the most sense.</li> <li>In this case, the alternate suggestion is to have a branch for the one-off machine and make the necessary changes in that branch.</li> <li>As updates are made to the main branch, merge main into the one-off branch. If ever there is an incompatibility between main and the one-off feature, then the feature would be adjusted within the one-off branch.</li> </ul>"},{"location":"VersionControl_8_Submodules/#submodule-workflow","title":"Submodule Workflow","text":"<ul> <li>Commit/push changes to the submodule repo as usual</li> <li>Commit/push changes to parent repo to update the commit reference (\"pointer\") to the submodule<ul> <li>The parent repo keeps records what commit hash it is currently using of the submodule. So, if you push a change to the submodule without committing the new reference commit value in the parent repo, then the parent repo will still be referencing the previous commit in the submodule.</li> </ul> </li> <li>This is how a submodule reference looks within Sourcetree, prior to staging the change. In this example, \"BaseProject\" is the submodule (child) repo.<ul> <li>Once this change is pushed to the parent repo, the parent repo is now using the commit starting with \"08fb\" on the submodule</li> </ul> </li> </ul>"},{"location":"VersionControl_8_Submodules/#detached-head","title":"Detached Head","text":"<ul> <li>When you use submodules, you have a higher risk if ending up on a detachd head. </li> <li>Make sure if you commit to the top-level project that you also commit any submodules that have changes to them.</li> <li>If you don\u2019t, then you\u2019ll end up on a detached head on the submodule repository<ul> <li>This means your latest changes within that repo will be reverted to the last commit to the top-level repository, which can be confusing. It also means that any new commits to the sub repository are not associated with any branch, which is not good!</li> </ul> </li> <li>To recover from a detached head: (Source)<ul> <li>Do NOT check out any other branch (stay on the detached head)</li> <li>Right click on your most recent commit in the detached head and select \"Branch\"</li> <li>Give the branch a name. Leave \"Specified commit:\" selected. Uncheck the \"Checkout New Branch\".</li> <li>Afterwards, confirm in SourceTree that the new branch is on your latest commit.</li> <li>Now you can checkout the develop branch and merge the branch you just created into it. Afterwards, delete that branch.</li> </ul> </li> </ul>"},{"location":"VersionControl_9_Hooks/","title":"Hooks","text":""},{"location":"VersionControl_9_Hooks/#overview","title":"Overview","text":"<p>Hooks are scripts that automatically run at certain git repository events. </p> <ul> <li>Basic definition</li> <li>Customization</li> <li>Summary</li> </ul> <p>There are two types of hooks:</p> <ol> <li>Local Hooks: for events related to committing or checking-out to your local repo</li> <li>Server Hooks: for events related to pushing changes to the remote server<ul> <li>Note that tasks accomplished via server hooks can (and arguably should) be accomplished by the build/automation server instead</li> </ul> </li> </ol>"},{"location":"VersionControl_9_Hooks/#location-and-samples","title":"Location and Samples","text":"<p>All hooks are located in the .git/hooks folder.</p> <ul> <li>The .git folder is located in the root directory of the repo</li> <li>Note that this is a hidden folder, so make sure those are shown in your file explorer</li> </ul> <p>Many sample hooks are pre-populated within the .git/hooks folder to use as a starting point.</p> <ul> <li>They are all of the \".sample\" file extension</li> <li>To activate a pre-made hook for your repo, simply remove the \".sample\" file extension</li> </ul> <p></p>"},{"location":"VersionControl_9_Hooks/#local-hooks","title":"Local Hooks","text":"<p>Overview of commonly used local hooks:</p> <ul> <li>pre-commit<ul> <li>Runs before you attempt to commit to the repository</li> <li>Useful for code quality checks (whitespace errors, modules OK not monitored, etc)</li> </ul> </li> <li>prepare-commit-msg<ul> <li>Runs after pre-commit</li> <li>Useful for prepopulating commit messages</li> </ul> </li> <li>commit-msg<ul> <li>Runs after the commit message</li> <li>Useful for checking commit message standards (reference JIRA issue)</li> </ul> </li> <li>post-commit<ul> <li>Runs after a commit</li> <li>Trigger local integration tests</li> </ul> </li> <li>post-checkout<ul> <li>Runs after a checkout</li> <li>Useful for cleaning workspace (clean AS project)</li> </ul> </li> </ul>"},{"location":"VersionControl_9_Hooks/#server-hooks","title":"Server Hooks","text":"<p>Overview of commonly used server hooks:</p> <ul> <li>pre-receive<ul> <li>Runs when someone attempts to push commits to the repository</li> <li>Enforce any development policy (code quality/standard checks, commit message checks, etc)</li> <li>Called once per push</li> </ul> </li> <li>update<ul> <li>Runs after pre-receive</li> <li>Called separately for each ref (branch) that was pushed</li> <li>Reject single ref\u2019s in a push instead of the entire push</li> </ul> </li> <li>post-receive<ul> <li>Runs after a successful push</li> <li>Useful for triggering continuous integration system (e.g., could automatically trigger the Jenkins build)</li> <li>Useful for notifications</li> </ul> </li> </ul>"}]}